{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle-challenge-05.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LMf7XJ8ZKvMI",
        "xrBfvek3eRDX",
        "KEM3vGiUchZ3",
        "BrNily2drusm",
        "ueUm9Y8vcQhl",
        "qLe05DkAn8gj",
        "WiiU8GRvjmpW",
        "ShPnUM_gKvMW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Virtual Environment",
      "language": "python",
      "name": "virtualenvironment"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kabrol98/PASSNYC-Data-Challenge/blob/master/kaggle_challenge_05.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "LMf7XJ8ZKvMI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "kQMLzJ8PMZKN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Going to import all libraries and upload all necessary files here.\n",
        "\n",
        "Uploading into colab. Setting up a virtual environment for myself is not an andeavor I'm interested in wasting this weekend on."
      ]
    },
    {
      "metadata": {
        "id": "Mp4l6P6sKvMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.models import load_model\n",
        "import io\n",
        "from google.colab import files\n",
        "import math\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rHTnX2_tSJmW",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "0d593010-b8ef-4e08-a332-35c7e96729df"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "school_data = pd.read_csv(io.StringIO(uploaded['2016 School Explorer.csv'].decode('utf-8')))\n",
        "# turnout_data = pd.read_csv(io.StringIO(uploaded['D5 SHSAT Registrations and Testers.csv'].decode('utf-8')))\n",
        "nytdf = pd.read_csv(io.StringIO(uploaded['nytdf.csv'].decode('utf-8')))\n",
        "middleschoolDirectory = pd.read_csv(io.StringIO(uploaded[\"2018_DOE_Middle_School_Directory.csv\"].decode('utf-8')))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4cf47e5b-9634-4438-9f0f-e13b2098cc49\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4cf47e5b-9634-4438-9f0f-e13b2098cc49\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 2016 School Explorer.csv to 2016 School Explorer (1).csv\n",
            "Saving 2016-2017_Monthly_Attendance.csv to 2016-2017_Monthly_Attendance (1).csv\n",
            "Saving 2018_DOE_Middle_School_Directory.csv to 2018_DOE_Middle_School_Directory (1).csv\n",
            "Saving D5 SHSAT Registrations and Testers.csv to D5 SHSAT Registrations and Testers (1).csv\n",
            "Saving nytdf.csv to nytdf (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r3I5z1EOafAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8d346938-ea29-4d30-d847-34cf0de0de16"
      },
      "cell_type": "code",
      "source": [
        "middleschoolDirectory.describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>district</th>\n",
              "      <th>geapps_prog1</th>\n",
              "      <th>swdapps_prog1</th>\n",
              "      <th>geappsperseat_prog1</th>\n",
              "      <th>swdappsperseat_prog1</th>\n",
              "      <th>swdseats_prog1</th>\n",
              "      <th>geseats_prog1</th>\n",
              "      <th>priority5_prog1</th>\n",
              "      <th>priority6_prog1</th>\n",
              "      <th>priority7_prog1</th>\n",
              "      <th>...</th>\n",
              "      <th>surveysafety</th>\n",
              "      <th>totalstudents</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Community Board</th>\n",
              "      <th>Council District</th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>BIN</th>\n",
              "      <th>BBL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>482.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>407.000000</td>\n",
              "      <td>402.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>356.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>218.000000</td>\n",
              "      <td>481.000000</td>\n",
              "      <td>481.000000</td>\n",
              "      <td>481.000000</td>\n",
              "      <td>481.000000</td>\n",
              "      <td>481.000000</td>\n",
              "      <td>481.000000</td>\n",
              "      <td>4.790000e+02</td>\n",
              "      <td>4.790000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>15.661826</td>\n",
              "      <td>391.691932</td>\n",
              "      <td>72.911980</td>\n",
              "      <td>5.987715</td>\n",
              "      <td>5.004975</td>\n",
              "      <td>18.236842</td>\n",
              "      <td>76.264045</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>83.759259</td>\n",
              "      <td>463.908257</td>\n",
              "      <td>10792.120582</td>\n",
              "      <td>40.739306</td>\n",
              "      <td>-73.913777</td>\n",
              "      <td>7.877339</td>\n",
              "      <td>24.006237</td>\n",
              "      <td>8207.266112</td>\n",
              "      <td>2.728300e+06</td>\n",
              "      <td>2.652594e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.371061</td>\n",
              "      <td>370.050901</td>\n",
              "      <td>49.346336</td>\n",
              "      <td>6.898800</td>\n",
              "      <td>5.050861</td>\n",
              "      <td>14.655398</td>\n",
              "      <td>51.671530</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>8.709119</td>\n",
              "      <td>443.787782</td>\n",
              "      <td>542.965137</td>\n",
              "      <td>0.087753</td>\n",
              "      <td>0.076714</td>\n",
              "      <td>4.542797</td>\n",
              "      <td>14.131892</td>\n",
              "      <td>22543.774242</td>\n",
              "      <td>1.190552e+06</td>\n",
              "      <td>1.147758e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>10001.000000</td>\n",
              "      <td>40.508284</td>\n",
              "      <td>-74.243428</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000811e+06</td>\n",
              "      <td>1.000160e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>192.750000</td>\n",
              "      <td>10451.000000</td>\n",
              "      <td>40.670986</td>\n",
              "      <td>-73.956716</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>2.005660e+06</td>\n",
              "      <td>2.026365e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>14.500000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>11102.000000</td>\n",
              "      <td>40.733514</td>\n",
              "      <td>-73.916655</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>369.000000</td>\n",
              "      <td>3.044493e+06</td>\n",
              "      <td>3.013670e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>24.000000</td>\n",
              "      <td>481.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>456.750000</td>\n",
              "      <td>11231.000000</td>\n",
              "      <td>40.822443</td>\n",
              "      <td>-73.875183</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>956.000000</td>\n",
              "      <td>3.413796e+06</td>\n",
              "      <td>3.084900e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>32.000000</td>\n",
              "      <td>4183.000000</td>\n",
              "      <td>432.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>204.000000</td>\n",
              "      <td>461.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2175.000000</td>\n",
              "      <td>11694.000000</td>\n",
              "      <td>40.899295</td>\n",
              "      <td>-73.712965</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>157902.000000</td>\n",
              "      <td>5.149609e+06</td>\n",
              "      <td>5.078940e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 150 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         district  geapps_prog1  swdapps_prog1  geappsperseat_prog1  \\\n",
              "count  482.000000    409.000000     409.000000           407.000000   \n",
              "mean    15.661826    391.691932      72.911980             5.987715   \n",
              "std      9.371061    370.050901      49.346336             6.898800   \n",
              "min      1.000000     33.000000       2.000000             1.000000   \n",
              "25%      8.000000    176.000000      41.000000             3.000000   \n",
              "50%     14.500000    291.000000      62.000000             4.000000   \n",
              "75%     24.000000    481.000000      91.000000             7.000000   \n",
              "max     32.000000   4183.000000     432.000000            80.000000   \n",
              "\n",
              "       swdappsperseat_prog1  swdseats_prog1  geseats_prog1  priority5_prog1  \\\n",
              "count            402.000000      418.000000     356.000000              0.0   \n",
              "mean               5.004975       18.236842      76.264045              NaN   \n",
              "std                5.050861       14.655398      51.671530              NaN   \n",
              "min                0.000000        0.000000       4.000000              NaN   \n",
              "25%                3.000000       11.000000      49.000000              NaN   \n",
              "50%                4.000000       16.000000      69.000000              NaN   \n",
              "75%                5.750000       22.000000      89.250000              NaN   \n",
              "max               58.000000      204.000000     461.000000              NaN   \n",
              "\n",
              "       priority6_prog1  priority7_prog1      ...       surveysafety  \\\n",
              "count              0.0              0.0      ...         216.000000   \n",
              "mean               NaN              NaN      ...          83.759259   \n",
              "std                NaN              NaN      ...           8.709119   \n",
              "min                NaN              NaN      ...          59.000000   \n",
              "25%                NaN              NaN      ...          79.000000   \n",
              "50%                NaN              NaN      ...          85.000000   \n",
              "75%                NaN              NaN      ...          90.000000   \n",
              "max                NaN              NaN      ...         100.000000   \n",
              "\n",
              "       totalstudents      Postcode    Latitude   Longitude  Community Board  \\\n",
              "count     218.000000    481.000000  481.000000  481.000000       481.000000   \n",
              "mean      463.908257  10792.120582   40.739306  -73.913777         7.877339   \n",
              "std       443.787782    542.965137    0.087753    0.076714         4.542797   \n",
              "min        38.000000  10001.000000   40.508284  -74.243428         1.000000   \n",
              "25%       192.750000  10451.000000   40.670986  -73.956716         4.000000   \n",
              "50%       266.000000  11102.000000   40.733514  -73.916655         8.000000   \n",
              "75%       456.750000  11231.000000   40.822443  -73.875183        12.000000   \n",
              "max      2175.000000  11694.000000   40.899295  -73.712965        18.000000   \n",
              "\n",
              "       Council District   Census Tract           BIN           BBL  \n",
              "count        481.000000     481.000000  4.790000e+02  4.790000e+02  \n",
              "mean          24.006237    8207.266112  2.728300e+06  2.652594e+09  \n",
              "std           14.131892   22543.774242  1.190552e+06  1.147758e+09  \n",
              "min            1.000000       1.000000  1.000811e+06  1.000160e+09  \n",
              "25%           12.000000     175.000000  2.005660e+06  2.026365e+09  \n",
              "50%           22.000000     369.000000  3.044493e+06  3.013670e+09  \n",
              "75%           36.000000     956.000000  3.413796e+06  3.084900e+09  \n",
              "max           51.000000  157902.000000  5.149609e+06  5.078940e+09  \n",
              "\n",
              "[8 rows x 150 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "NZkwh83rKvMP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data loaded from the two datasets provided and the NYT SHSAT article\n",
        "\n",
        "For some reason, ther index schooldbn is not workiong on the mioddle school directory dataset."
      ]
    },
    {
      "metadata": {
        "id": "PwrAlJ9eKvMP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# schoolExplorer = pd.read_csv(\"kaggle-data/2016 School Explorer.csv\", encoding = 'utf-8')\n",
        "# registrationTesters = pd.read_csv(\"kaggle-data/D5 SHSAT Registrations and Testers.csv\", encoding= 'utf-8')\n",
        "# nytdf = pd.read_csv(\"kaggle-data/nytdf.csv\", encoding = 'utf-8')\n",
        "# highschoolDirectory = pd.read_csv(\"kaggle-data/2017-doe-high-school-directory.csv\",encoding = 'utf-8')\n",
        "# middleschoolDirectory = pd.read_csv(\"kaggle-data/2018_DOE_Middle_School_Directory.csv\",encoding = 'utf-8')\n",
        "\n",
        "schoolExplorer = school_data\n",
        "\n",
        "\n",
        "# highschoolDirectory = highschoolDirectory.set_index('dbn')\n",
        "middleschoolDirectory = middleschoolDirectory.set_index('schooldbn')\n",
        "\n",
        "\n",
        "schoolExplorer = schoolExplorer.set_index('Location Code')\n",
        "nytdf = nytdf.set_index('DBN')\n",
        "\n",
        "explorer_nyt = schoolExplorer.join(nytdf)\n",
        "nytCombined = nytdf.join(schoolExplorer)\n",
        "\n",
        "# nytCombined.to_csv(\"kaggle-data/combined.csv\", index=False)\n",
        "nytCombined.describe()\n",
        "testErrorArray = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xrBfvek3eRDX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Picking, amending, and converting the necessary features into usable values for a predictive model."
      ]
    },
    {
      "metadata": {
        "id": "8qMLdsyIKvMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "27cc633c-b1fa-4243-c5a8-e3301d35c9f9"
      },
      "cell_type": "code",
      "source": [
        "#Pick features\n",
        "features = ['Percent of Students Chronically Absent','Average Math Proficiency','Economic Need Index','Average ELA Proficiency', 'Latitude', 'Longitude', 'NumSHSATTestTakers', 'Student Attendance Rate']\n",
        "target = 'NumSHSATTestTakers'\n",
        "\n",
        "nytCombinedFiltered = nytCombined.query('NumSHSATTestTakers != 0')\n",
        "\n",
        "nytCombinedFiltered[features].describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Average Math Proficiency</th>\n",
              "      <th>Economic Need Index</th>\n",
              "      <th>Average ELA Proficiency</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>NumSHSATTestTakers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>530.000000</td>\n",
              "      <td>531.000000</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>536.000000</td>\n",
              "      <td>536.000000</td>\n",
              "      <td>537.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.668849</td>\n",
              "      <td>0.657750</td>\n",
              "      <td>2.574906</td>\n",
              "      <td>40.738840</td>\n",
              "      <td>-73.915875</td>\n",
              "      <td>47.204842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.486156</td>\n",
              "      <td>0.191868</td>\n",
              "      <td>0.375443</td>\n",
              "      <td>0.086535</td>\n",
              "      <td>0.075129</td>\n",
              "      <td>61.158551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.890000</td>\n",
              "      <td>0.059000</td>\n",
              "      <td>1.910000</td>\n",
              "      <td>40.507803</td>\n",
              "      <td>-74.243221</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.270000</td>\n",
              "      <td>0.545500</td>\n",
              "      <td>2.280000</td>\n",
              "      <td>40.671637</td>\n",
              "      <td>-73.955888</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.610000</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>2.490000</td>\n",
              "      <td>40.728875</td>\n",
              "      <td>-73.919367</td>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.980000</td>\n",
              "      <td>0.806500</td>\n",
              "      <td>2.790000</td>\n",
              "      <td>40.820391</td>\n",
              "      <td>-73.880919</td>\n",
              "      <td>46.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.190000</td>\n",
              "      <td>0.938000</td>\n",
              "      <td>3.930000</td>\n",
              "      <td>40.899321</td>\n",
              "      <td>-73.713022</td>\n",
              "      <td>394.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Average Math Proficiency  Economic Need Index  Average ELA Proficiency  \\\n",
              "count                530.000000           531.000000               530.000000   \n",
              "mean                   2.668849             0.657750                 2.574906   \n",
              "std                    0.486156             0.191868                 0.375443   \n",
              "min                    1.890000             0.059000                 1.910000   \n",
              "25%                    2.270000             0.545500                 2.280000   \n",
              "50%                    2.610000             0.710000                 2.490000   \n",
              "75%                    2.980000             0.806500                 2.790000   \n",
              "max                    4.190000             0.938000                 3.930000   \n",
              "\n",
              "         Latitude   Longitude  NumSHSATTestTakers  \n",
              "count  536.000000  536.000000          537.000000  \n",
              "mean    40.738840  -73.915875           47.204842  \n",
              "std      0.086535    0.075129           61.158551  \n",
              "min     40.507803  -74.243221            6.000000  \n",
              "25%     40.671637  -73.955888           15.000000  \n",
              "50%     40.728875  -73.919367           26.000000  \n",
              "75%     40.820391  -73.880919           46.000000  \n",
              "max     40.899321  -73.713022          394.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "KEM3vGiUchZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper functions\n",
        "Set of functions to normalize data and remove percentages."
      ]
    },
    {
      "metadata": {
        "id": "wOz_0BSYcf36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert string valued percentages into floats within [0,1]\n",
        "def removePercent(df,columnNames):\n",
        "  for i in range(len(columnNames)):\n",
        "    col_string = df[columnNames[i]].str\n",
        "    df[columnNames[i]] = col_string.rstrip('%').astype('float') / 100.0\n",
        "    pass\n",
        "  return df\n",
        "  \n",
        "# for values in arbitrary ranges, normalize across [-1,1]\n",
        "def normalize_series(df, labels):\n",
        "  for label in labels:\n",
        "#     for sigma = 1 standard deviation, ~97% of datapoints should be within [-3sigma,sigma]\n",
        "    df[label] = (df[label] - df[label].mean()) / (3 * df[label].std())\n",
        "    pass\n",
        "  return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWuzcicOfX_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "9bfad676-85cb-4a64-eff3-d43f9684f47d"
      },
      "cell_type": "code",
      "source": [
        "# Applying helpers to dataset\n",
        "\n",
        "nytApplyFilters = removePercent(nytCombinedFiltered.copy(), ['Student Attendance Rate', 'Percent of Students Chronically Absent'])\n",
        "\n",
        "nytApplyFilters = normalize_series(nytApplyFilters, ['Average Math Proficiency', 'Average ELA Proficiency'])\n",
        "\n",
        "nytApplyFilters = nytApplyFilters.dropna(subset=[target])\n",
        "nytApplyFilters.fillna(0,inplace = True)\n",
        "\n",
        "nytApplyFilters[features].describe()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Percent of Students Chronically Absent</th>\n",
              "      <th>Average Math Proficiency</th>\n",
              "      <th>Economic Need Index</th>\n",
              "      <th>Average ELA Proficiency</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>NumSHSATTestTakers</th>\n",
              "      <th>Student Attendance Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>537.000000</td>\n",
              "      <td>5.370000e+02</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>5.370000e+02</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.196108</td>\n",
              "      <td>7.939025e-17</td>\n",
              "      <td>0.650400</td>\n",
              "      <td>-2.514025e-16</td>\n",
              "      <td>40.662977</td>\n",
              "      <td>-73.778229</td>\n",
              "      <td>47.204842</td>\n",
              "      <td>0.913762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.150459</td>\n",
              "      <td>3.311496e-01</td>\n",
              "      <td>0.202953</td>\n",
              "      <td>3.311496e-01</td>\n",
              "      <td>1.760135</td>\n",
              "      <td>3.190588</td>\n",
              "      <td>61.158551</td>\n",
              "      <td>0.151724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.340184e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.903301e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-74.243221</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>-2.666146e-01</td>\n",
              "      <td>0.538000</td>\n",
              "      <td>-2.618291e-01</td>\n",
              "      <td>40.670886</td>\n",
              "      <td>-73.955847</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.170000</td>\n",
              "      <td>-3.349339e-02</td>\n",
              "      <td>0.708000</td>\n",
              "      <td>-7.538267e-02</td>\n",
              "      <td>40.728596</td>\n",
              "      <td>-73.919072</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.270000</td>\n",
              "      <td>2.133409e-01</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>1.820910e-01</td>\n",
              "      <td>40.820192</td>\n",
              "      <td>-73.880280</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.042978e+00</td>\n",
              "      <td>0.938000</td>\n",
              "      <td>1.203107e+00</td>\n",
              "      <td>40.899321</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>394.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Percent of Students Chronically Absent  Average Math Proficiency  \\\n",
              "count                              537.000000              5.370000e+02   \n",
              "mean                                 0.196108              7.939025e-17   \n",
              "std                                  0.150459              3.311496e-01   \n",
              "min                                  0.000000             -5.340184e-01   \n",
              "25%                                  0.100000             -2.666146e-01   \n",
              "50%                                  0.170000             -3.349339e-02   \n",
              "75%                                  0.270000              2.133409e-01   \n",
              "max                                  1.000000              1.042978e+00   \n",
              "\n",
              "       Economic Need Index  Average ELA Proficiency    Latitude   Longitude  \\\n",
              "count           537.000000             5.370000e+02  537.000000  537.000000   \n",
              "mean              0.650400            -2.514025e-16   40.662977  -73.778229   \n",
              "std               0.202953             3.311496e-01    1.760135    3.190588   \n",
              "min               0.000000            -5.903301e-01    0.000000  -74.243221   \n",
              "25%               0.538000            -2.618291e-01   40.670886  -73.955847   \n",
              "50%               0.708000            -7.538267e-02   40.728596  -73.919072   \n",
              "75%               0.806000             1.820910e-01   40.820192  -73.880280   \n",
              "max               0.938000             1.203107e+00   40.899321    0.000000   \n",
              "\n",
              "       NumSHSATTestTakers  Student Attendance Rate  \n",
              "count          537.000000               537.000000  \n",
              "mean            47.204842                 0.913762  \n",
              "std             61.158551                 0.151724  \n",
              "min              6.000000                 0.000000  \n",
              "25%             15.000000                 0.920000  \n",
              "50%             26.000000                 0.940000  \n",
              "75%             46.000000                 0.960000  \n",
              "max            394.000000                 1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "MaEejyNxoPyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setting up features as a vector\n",
        "# Separating training and testing for k-fold vallidation\n",
        "num_folds = 10\n",
        "N = nytApplyFilters.shape[0]\n",
        "\n",
        "test_set = nytApplyFilters[0: N / num_folds]\n",
        "train_set = nytApplyFilters[N / num_folds : N]\n",
        "\n",
        "test_set = test_set.filter(features)\n",
        "train_set = train_set.filter(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mkygk68pq3Q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e925b76-eb28-458b-b0cc-84a525915809"
      },
      "cell_type": "code",
      "source": [
        "# X and Y from train sets\n",
        "\n",
        "X = train_set.drop(target, axis=1).values\n",
        "\n",
        "# Using the output as a percentage\n",
        "\n",
        "Y = train_set[[target]].values\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(484, 7)\n",
            "(484, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BrNily2drusm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Neural Network\n"
      ]
    },
    {
      "metadata": {
        "id": "4QFsFK9wrt0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "96c31223-fd64-4046-f5bf-5b1b72d670e2"
      },
      "cell_type": "code",
      "source": [
        "numFeatures = len(features)\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "activationFuntion = 'relu'\n",
        "model.add(Dense(20, input_dim=numFeatures-1, activation='relu'))\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "# model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','accuracy'])\n",
        "\n",
        "\n",
        "#Train\n",
        "model.fit(\n",
        "    X,\n",
        "    Y,\n",
        "    epochs=200,\n",
        "    shuffle=True,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "\n",
        "X_test = test_set.drop(target, axis=1).values\n",
        "Y_test = test_set[[target]].values\n",
        "\n",
        "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "testErrorArray.append(test_error_rate)\n",
        "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n",
        "print(\"Here: \\n%s: %.8f%%\" % (model.metrics_names[2], test_error_rate[2]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean squared error (MSE) for the test data set is: [28634.947302476416, 142.72677036501327, 0.0]\n",
            "Here: \n",
            "acc: 0.00000000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W99G64DAUbSJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Best \"acc\" achieved by this prediction network: 0.01887%.\n",
        "Best MSE on real valued Num of SHSAT Test Takers: 142.65"
      ]
    },
    {
      "metadata": {
        "id": "odaWq-BYUmLn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Radial Basis Function (RBF) Model\n",
        "\n",
        "Going to try a Radial Basis Function Model to minimize in-sample MSE.\n",
        "\n",
        "Value to beat: 142.65."
      ]
    },
    {
      "metadata": {
        "id": "k8ev1VnH7v0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Process\n",
        "\n",
        "#### Step 1:\n",
        "K-means clustering on feature sets.\n",
        "\n",
        "#### Step 2:\n",
        "Define the RBF equation as follows.\n",
        "\n",
        "\\begin{equation}\n",
        "\\Large\n",
        "y = \\sum_{k=1}^K w_ke^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_k} \\| ^ 2}\n",
        "\\end{equation}\n",
        "\n",
        "with precision rate $\\lambda$ where $\\mu_k$ is a mean point for all K- means.\n",
        "\n",
        "#### Step 3:\n",
        "Build model to find least square values for all weights $w_k$.\n",
        "\n",
        "#### Step 4:\n",
        "Test model with different precision rates, try to minimize cost."
      ]
    },
    {
      "metadata": {
        "id": "ueUm9Y8vcQhl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1: K means clustering"
      ]
    },
    {
      "metadata": {
        "id": "01zZZBP_MCDl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Lloyd's algorithm\n",
        "I'm going to implement K-means clustering using Lloyd's algorithm on the feature vector $ \\mathbf{x} $,\n",
        "using the following iterative implementation for Lloyd's algotihm.\n",
        "\n",
        "$ \\mathbf{\\mu_0} = random \\in {\\mathbf{x}}$\n",
        "\n",
        "$ \\mathbf{S_0} =  \\{ \\mathbf{x} : \\forall \\mu, \\| \\mathbf{x} - \\mathbf{\\mu_0} \\| \\leq \\| \\mathbf{x} - \\mathbf{\\mu} \\|\\} $\n",
        "\n",
        "$ \\mathbf{\\mu_{n+1}} = \\frac{1}{\\mathbf{\\|S_n\\|}} \\sum_{\\mathbf{x} \\in \\mathbf{S_n}} \\mathbf{x}$\n",
        "\n",
        "$ \\mathbf{S_{n+1}} =  \\{ \\mathbf{x} : \\forall \\mu, \\| \\mathbf{x} - \\mathbf{\\mu_{n+1}} \\| \\leq \\| \\mathbf{x} - \\mathbf{\\mu} \\|\\} $\n"
      ]
    },
    {
      "metadata": {
        "id": "qMIPF-qxcOZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Lloyd's algorithm: Implmentation.\n",
        "# Assume feature engineering has been done.\n",
        "class LloydMeans:\n",
        "  \n",
        "  def __init__ (self, k, df, labels):\n",
        "    self.pointMatrix = df[labels].as_matrix()\n",
        "    self.df = df\n",
        "    self.labels = labels\n",
        "    self.k = k\n",
        "    pass\n",
        "  \n",
        "  def assign_means(self, num_trials, num_iterations):\n",
        "    best_error = float(\"inf\") # Best error is positive infinity\n",
        "    best_mu = []\n",
        "    best_meanSet = []\n",
        "    clustered_features = self.labels\n",
        "    pointMatrix = self.pointMatrix\n",
        "    k = self.k\n",
        "    df = self.df\n",
        "\n",
        "    for trial in range(num_trials):\n",
        "      mu = self.init_mu(df, clustered_features, k)\n",
        "\n",
        "      for i in range(num_iterations):\n",
        "        #iteratively update the clusters and cluster means nunm_iterations times\n",
        "        meanSet = self.update_clusters(pointMatrix, mu, k)\n",
        "        mu = self.update_cluster_points(meanSet, mu, k)\n",
        "        pass\n",
        "\n",
        "      #calculate error of current mu model\n",
        "      model_error = self.calculate_total_error(meanSet, mu)\n",
        "\n",
        "      print(\"MSE for trial {} : {}\".format(trial, model_error))\n",
        "\n",
        "      #always take the best model w/ minimum error\n",
        "      if(model_error < best_error):\n",
        "        best_error = model_error\n",
        "        best_mu = mu\n",
        "        best_meanSet = meanSet\n",
        "        pass\n",
        "      pass\n",
        "    print(\"Best error is {}\".format(best_error))\n",
        "#     df = assign_final_clusters(pointMatrix, best_mu, k, self.df)\n",
        "    return best_mu\n",
        "  \n",
        "  def normalize_matrix(self, df, labels):\n",
        "    mat = df[labels].as_matrix()\n",
        "    # transform all datapoints so ~97% of values are in [-1, 1]\n",
        "    for i in range(mat.shape[0]):\n",
        "      for j in range(mat.shape[1]):\n",
        "        mat[i][j] = (mat[i][j] - df[labels[j]].mean()) / (3 * df[labels[j]].std())\n",
        "        pass\n",
        "      pass\n",
        "    return mat\n",
        "\n",
        "  def init_mu(self, df, labels, k):\n",
        "      mu = np.zeros((k, len(labels)))\n",
        "      for i in range(len(labels)):\n",
        "        for j in range(k):\n",
        "#           initialize random float in [-1, 1]\n",
        "          offset = np.random.ranf() * 6 - 3\n",
        "          mu[j][i] = df[labels[i]].mean() + offset\n",
        "      return mu\n",
        "\n",
        "  def update_clusters(self, pointMatrix, mu, k):\n",
        "    meanSet = [[] for i in range(k)]\n",
        "  #   iterate over points\n",
        "    for i in range(pointMatrix.shape[0]):\n",
        "      minIndex = 0\n",
        "      minDistance = np.linalg.norm(pointMatrix[i] - mu[minIndex])\n",
        "  #     iterate over mu (mean points)\n",
        "      for j in range(k):\n",
        "        dist = np.linalg.norm(pointMatrix[i] - mu[j])\n",
        "  #       pick j with the minimum distance from i\n",
        "        if(dist < minDistance):\n",
        "          minDistance = dist\n",
        "          minIndex = j\n",
        "          pass\n",
        "        pass\n",
        "    #   Add point i to mu[j]'s cluster'\n",
        "      meanSet[minIndex].append(pointMatrix[i])\n",
        "      pass\n",
        "    return meanSet\n",
        "\n",
        "  def assign_final_clusters(self, pointMatrix, mu, k, df):\n",
        "  #   iterate over points (repeating update_clusters)\n",
        "    for i in range(pointMatrix.shape[0]):\n",
        "      minIndex = 0\n",
        "      minDistance = np.linalg.norm(pointMatrix[i] - mu[minIndex])\n",
        "  #     iterate over mu (mean points)\n",
        "      for j in range(k):\n",
        "        dist = np.linalg.norm(pointMatrix[i] - mu[j])\n",
        "  #       pick j with the minimum distance from i\n",
        "        if(dist < minDistance):\n",
        "          minDistance = dist\n",
        "          minIndex = j\n",
        "          pass\n",
        "        pass\n",
        "    #   Assign final cluster values to dataframe\n",
        "      df.loc[df.index[i], 'cluster'] = minIndex\n",
        "      pass\n",
        "    return df\n",
        "\n",
        "  def update_cluster_points(self, meanSet, mu, k):\n",
        "  #   iterate over mu\n",
        "    for i in range(k):\n",
        "      set_sum = np.zeros(mu[i].shape)\n",
        "  #     iterate over mu[i]'s cluster'\n",
        "      for j in range(len(meanSet[i])):\n",
        "        # sum up all the positions of each point\n",
        "        set_sum += meanSet[i][j]\n",
        "        pass\n",
        "      # update mu to the average of each point in mu's cluster\n",
        "      if len(meanSet[i]) != 0:\n",
        "        mu[i] = set_sum / len(meanSet[i])\n",
        "        pass\n",
        "      pass\n",
        "    return mu\n",
        "\n",
        "  def calculate_total_error(self, meanSet, mu):\n",
        "    mserror = 0\n",
        "    N = 0\n",
        "    for i in range(self.k):\n",
        "      for j in range(len(meanSet[i])):\n",
        "        error = np.linalg.norm(meanSet[i][j] - mu[i])\n",
        "        mserror += error * error\n",
        "        N += 1\n",
        "        pass\n",
        "      pass\n",
        "    return mserror / N\n",
        "  \n",
        "  pass\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yyosdWSgSk_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ad9be1d0-db9c-4af5-d2af-f994f9ef8060"
      },
      "cell_type": "code",
      "source": [
        "# Lloyd's Algorithm- application\n",
        "\n",
        "# Set up X as independent dataframe with features vector\n",
        "clusterDF = train_set\n",
        "featureLabels = copy.deepcopy(features)\n",
        "featureLabels.remove(target)\n",
        "\n",
        "# Let K increase logarithmically with N.\n",
        "# This will help optimize clustering and create good representatives.\n",
        "\n",
        "train_N = clusterDF.shape[0]\n",
        "K = 10 * int(math.floor(math.log(train_N)))\n",
        "\n",
        "lloyd = LloydMeans(K, clusterDF, featureLabels)\n",
        "mu = lloyd.assign_means(num_iterations = 50, num_trials = 10)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE for trial 0 : 0.254862599608\n",
            "MSE for trial 1 : 0.104558737557\n",
            "MSE for trial 2 : 0.213666324099\n",
            "MSE for trial 3 : 0.105426345453\n",
            "MSE for trial 4 : 0.0776927485398\n",
            "MSE for trial 5 : 0.0631433716969\n",
            "MSE for trial 6 : 0.105884978989\n",
            "MSE for trial 7 : 0.0776927485398\n",
            "MSE for trial 8 : 0.104558737557\n",
            "MSE for trial 9 : 0.254862599608\n",
            "Best error is 0.0631433716969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qLe05DkAn8gj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2: Defining the Radial Basis Function"
      ]
    },
    {
      "metadata": {
        "id": "2pCx-7iyL7or",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is the function again, just to remind myself, and because LaTEX is awesome.\n",
        "\n",
        "\\begin{equation}\n",
        "\\large\n",
        "y = \\sum_{k=1}^K w_ke^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_k} \\| ^ 2}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "metadata": {
        "id": "iwKcfGqHnatV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _predict (mu, w, x, precision_rate):\n",
        "#   Sum over mu\n",
        "  sum = 0\n",
        "  for i in range(mu.shape[0]):\n",
        "#     distance between point x and mu\n",
        "    dist = np.linalg.norm(x[i] - mu[i])\n",
        "#   square distance, multiply by lambda\n",
        "    exponent = (- precision_rate) * dist * dist\n",
        "#   multiply exponent by weight, add to total\n",
        "    sum += (w[i] * math.exp(exponent))\n",
        "    pass\n",
        "  return sum\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1C_y7Kbv-wt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a good start, but we have to visualize this as a matrix instead of a function before we can solve for $ \\mathbf{w} $\n",
        "\n",
        "We're going to do this by creating the following matrix:\n",
        "\n",
        "$\\mathbf{A_{1,K}} = \n",
        "\\begin{pmatrix} \n",
        "e^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_1} \\| ^ 2} & \\cdots & e^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_K} \\| ^ 2}\n",
        "\\end{pmatrix}$\n",
        "\n",
        "This way, the new equation is:\n",
        "$\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix} \n",
        "e^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_1} \\| ^ 2} & \\cdots & e^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_K} \\| ^ 2}\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "w_1 \\\\ \\vdots \\\\ w_K\n",
        "\\end{bmatrix} = y\n",
        "\\end{equation}\n",
        "$\n",
        "\n",
        "or\n",
        "\n",
        "$\\begin{equation} \\mathbf{Aw} = y \\end{equation}$"
      ]
    },
    {
      "metadata": {
        "id": "DvOVtGX2ogU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict (mu, w, x, precision_rate):\n",
        "  A = np.zeros((1, mu.shape[0]))\n",
        "  for i in range(mu.shape[0]):\n",
        "#   distance between point x and mu\n",
        "    dist = np.linalg.norm(x - mu[i])\n",
        "#   square distance, multiply by lambda\n",
        "    exponent = (- precision_rate) * dist * dist\n",
        "    A[0][i] = math.exp(exponent)\n",
        "    pass\n",
        "  return A.dot(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WiiU8GRvjmpW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3: Training.\n"
      ]
    },
    {
      "metadata": {
        "id": "6YnFaazULwcq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is going to be the most fun part.\n",
        "Extend our previous matrix $ \\mathbf{A} $ to all N points in our dataset, creating a K by N matrix.\n",
        "\n",
        "$\\mathbf{A_{N,K}} = \n",
        "\\begin{bmatrix} \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_1} \\| ^ 2} & \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_2} \\| ^ 2} & \\cdots & \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_K} \\| ^ 2} \n",
        "\\\\\n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_1} \\| ^ 2} & \n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_2} \\| ^ 2} & \\cdots &\n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_K} \\| ^ 2}\n",
        "\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\n",
        "\\\\\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_1} \\| ^ 2} &\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_2} \\| ^ 2} &\\cdots &\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_K} \\| ^ 2} \n",
        "\\end{bmatrix}$\n",
        "\n",
        "Now,\n",
        "\n",
        "$\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix} \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_1} \\| ^ 2} & \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_2} \\| ^ 2} & \\cdots & \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_K} \\| ^ 2} \n",
        "\\\\\n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_1} \\| ^ 2} & \n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_2} \\| ^ 2} & \\cdots &\n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_K} \\| ^ 2}\n",
        "\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\n",
        "\\\\\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_1} \\| ^ 2} &\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_2} \\| ^ 2} &\\cdots &\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_K} \\| ^ 2} \n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_K\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N\n",
        "\\end{bmatrix}\n",
        "\\end{equation}$\n",
        "\n",
        "or,\n",
        "\n",
        "$ \\mathbf{Aw = y} $\n",
        "\n",
        "So, to solve for $ \\mathbf{w} $ given a reasonable lambda we use the old Math 415 least squares regression equation\n",
        "\n",
        "$\\begin{equation}\n",
        "\\mathbf{w = (A^TA)^{-1}A^Ty}\n",
        "\\end{equation}\n",
        "$\n",
        "\n",
        "We're also going to write a loss function to look for a good MSE"
      ]
    },
    {
      "metadata": {
        "id": "5s3asd572CnR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train (X, Y, precision_rate, mu):\n",
        "  A = np.zeros((X.shape[0], mu.shape[0]))\n",
        "#   iterate over X\n",
        "  for i in range(X.shape[0]):\n",
        "#     iterate over mu\n",
        "    for j in range(mu.shape[0]):\n",
        "#     create vectors for x and mu\n",
        "      _x = np.transpose([X[i]])\n",
        "      _mu = np.transpose([mu[j]])\n",
        "#     Take the distance between point x and mu\n",
        "      dist = np.linalg.norm(_x - _mu)\n",
        "  #   square distance, multiply by lambda\n",
        "      exponent = (- precision_rate) * dist * dist\n",
        "      A[i][j] = math.exp(exponent)\n",
        "      pass\n",
        "    pass\n",
        "# Now we have A, let's get the appropriate transformation for y\n",
        "  trans = np.transpose(A).dot(A).dot(np.transpose(A))\n",
        "  return trans.dot(Y)\n",
        "  \n",
        "  \n",
        "def get_loss(X, Y, precision_rate, mu, w):\n",
        "  mse = 0\n",
        "  count = 0\n",
        "  for i in range(X.shape[0]):\n",
        "    predicted = predict(mu, w, X[i], precision_rate)\n",
        "    err = Y[i] - predicted\n",
        "    mse += err * err\n",
        "    count += 1\n",
        "    pass\n",
        "  res = mse / count\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXYFITEc4rVX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4: Application\n",
        "I've now written more latex than code and tested none of the code. Let's see if anything happens.\n",
        "I'm going to put everything in a for loop that tries lambdas ranging between 0.1 and 2."
      ]
    },
    {
      "metadata": {
        "id": "w5rKOr334pm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "47a2c09c-906c-43b1-b869-8488fdd5ad65"
      },
      "cell_type": "code",
      "source": [
        "step = 0.0625\n",
        "precision_rate = 84.5\n",
        "X = train_set.drop(target, axis=1).values\n",
        "Y = train_set[[target]].values\n",
        "\n",
        "test_X = test_set.drop(target, axis=1).values\n",
        "test_Y = test_set[[target]].values\n",
        "\n",
        "best_precision = precision_rate\n",
        "best_error = float('inf')\n",
        "\n",
        "for i in range(5):\n",
        "#   Train for given precision rate\n",
        "  w = train(X, Y, precision_rate, mu)\n",
        "#   Get the error\n",
        "  current_error = get_loss(test_X, test_Y, precision_rate, mu, w)\n",
        "  print('MSE for lambda {} was {}'.format(precision_rate, current_error))\n",
        "  \n",
        "#   Replace the best error and rate if a better set is found\n",
        "  if current_error < best_error:\n",
        "    best_error = current_error\n",
        "    best_precision = precision_rate\n",
        "    pass\n",
        "  precision_rate += step\n",
        "  pass\n",
        "\n",
        "print('Best MSE was {} with precision rate {}'.format(best_error, best_precision))\n",
        "  "
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE for lambda 84.5 was [[41989.73420287]]\n",
            "MSE for lambda 84.5625 was [[41989.17703309]]\n",
            "MSE for lambda 84.625 was [[41988.69360827]]\n",
            "MSE for lambda 84.6875 was [[41988.28299636]]\n",
            "MSE for lambda 84.75 was [[41987.9442752]]\n",
            "Best MSE was [[41987.9442752]] with precision rate 84.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0q8gGiVkIZ4c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conclusion:\n",
        "...Fuck."
      ]
    },
    {
      "metadata": {
        "id": "NZmSpGuTKeoH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "...in case the code block's output isn't visible, this is what it looks like:\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "MSE for lambda 84.5 was [[41989.73420287]]\n",
        "MSE for lambda 84.5625 was [[41989.17703309]]\n",
        "MSE for lambda 84.625 was [[41988.69360827]]\n",
        "MSE for lambda 84.6875 was [[41988.28299636]]\n",
        "MSE for lambda 84.75 was [[41987.9442752]]\n",
        "Best MSE was [[41987.9442752]] with precision rate 84.75\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iuoGZY80Lnwj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Possible issues:\n",
        " - N too small.\n",
        " - K too small.\n",
        " - Features are too few.\n",
        " - lambda uniform across means.\n",
        " - model not complex enough.\n",
        " - Some stupid mistake somewhere scales values wrong. You know, by a factor of $10^5$.\n",
        " \n",
        "#### Possible Solutions:\n",
        "  - Fuck this dataset. This dataset is horrible. 400 points, 7 features.\n",
        "  - Try to find/ implement variable lambda, and use iterative algorithm to regress w and lambda\n",
        "  - Implement RBF Network with multiple layers. This would be ridiculous in terms of debugging and time commitment."
      ]
    },
    {
      "metadata": {
        "id": "ShPnUM_gKvMW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Kush's Network\n",
        "\n",
        "The rationale behind creating a neural network with the NumofSHSATTestTakers is to determine the most probable schools which would have more test takers and then predict other schools' probable students. Following which we can rank each school depending on how diverse they are"
      ]
    },
    {
      "metadata": {
        "id": "jtqSY0DhKvMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Filter the dataset to remove any schools without any SHSAT Test takers\n",
        "\n",
        "features = ['TestTakersPercentage','ELA8thGrade4s','Math8thGrade4s','Percent of Students Chronically Absent','Average Math Proficiency','Economic Need Index','District','Average ELA Proficiency']\n",
        "\n",
        "nytCombinedFiltered = nytCombined.query(\"NumSHSATTestTakers !=0\")\n",
        "\n",
        "Math8thGrade4s = pd.Series(nytCombinedFiltered[ 'Grade 8 Math 4s - All Students']/(nytCombinedFiltered[ 'Grade 8 Math - All Students Tested']*1.0))\n",
        "ELA8thGrade4s = pd.Series(nytCombinedFiltered[ 'Grade 8 ELA 4s - All Students']/(nytCombinedFiltered[ 'Grade 8 ELA - All Students Tested']*1.0))\n",
        "TestTakersPercentage = pd.Series(nytCombinedFiltered['NumSHSATTestTakers']/(nytCombinedFiltered[ 'Grade 8 Math - All Students Tested']*1.0))\n",
        "\n",
        "nytCombinedFiltered = nytCombinedFiltered.assign(Math8thGrade4s = Math8thGrade4s)\n",
        "nytCombinedFiltered = nytCombinedFiltered.assign(ELA8thGrade4s = ELA8thGrade4s)\n",
        "nytCombinedFiltered = nytCombinedFiltered.assign(TestTakersPercentage = TestTakersPercentage)\n",
        "\n",
        "\n",
        "def removePercent(df,columnName):\n",
        "    df[columnName] = df[columnName].str.rstrip('%').astype('float') / 100.0\n",
        "    features.append(columnName)\n",
        "    return\n",
        "\n",
        "removePercent(nytCombinedFiltered,'Student Attendance Rate')\n",
        "removePercent(nytCombinedFiltered,'Percent of Students Chronically Absent')\n",
        "\n",
        "nytCombinedFiltered.fillna(0,inplace = True)\n",
        "nytCombinedFiltered = nytCombinedFiltered.replace([np.inf, -np.inf], np.nan)\n",
        "nytCombinedFiltered = nytCombinedFiltered.dropna(subset=['TestTakersPercentage'])\n",
        "# nytCombinedFiltered.fillna(1,inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhD42TLrKvMa",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb004191-556d-405b-8f34-be8097529069"
      },
      "cell_type": "code",
      "source": [
        "numFeatures = len(features)\n",
        "print(numFeatures)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rWlZMVr6KvMc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# nytCombinedFiltered['Student Attendance Rate']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p476LTV9KvMg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We split the Combined and filtered dataset to training and testing datasets, 60 each\n",
        "datasetSplit = 150\n",
        "\n",
        "nytCombinedFilteredTraining = nytCombinedFiltered[0:datasetSplit]\n",
        "nytCombinedFilteredTesting = nytCombinedFiltered[datasetSplit:]\n",
        "\n",
        "# Only pick out the columns that we want, ie: the ones with numeric values, we can still access the exact school name cause of the index\n",
        "\n",
        "nytTraining = nytCombinedFilteredTraining.filter(features)\n",
        "nytTesting = nytCombinedFilteredTesting.filter(features)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2RZ4Jdv2KvMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# list(nytTesting)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YcUQcNSlKvMl",
        "colab_type": "code",
        "colab": {},
        "outputId": "06851e04-324b-46f1-f597-86941a225e9b"
      },
      "cell_type": "code",
      "source": [
        "# Scale the inputs and outputs to a suitable small range\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Scale both the training inputs and outputs\n",
        "scaled_training = scaler.fit_transform(nytTraining)\n",
        "scaled_testing = scaler.transform(nytTesting)\n",
        "\n",
        "scaled_training_df = pd.DataFrame(scaled_training, columns= nytTraining.columns.values)\n",
        "scaled_testing_df = pd.DataFrame(scaled_testing, columns=nytTesting.columns.values)\n",
        "\n",
        "scaled_training_df.to_csv(\"kaggle-data/training_scaled.csv\", index=False)\n",
        "scaled_testing_df.to_csv(\"kaggle-data/testing_scaled.csv\", index=False)\n",
        "\n",
        "print(\"Note: Number of SHSAT Taker values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[0], scaler.min_[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: Number of SHSAT Taker values were scaled by multiplying by 0.1331344397 and adding -0.006340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DSQzgmwYKvMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This is the training of the model\n",
        "\n",
        "#This didnt work trying not the scaled values\n",
        "\n",
        "X = scaled_training_df.drop('TestTakersPercentage', axis=1).values\n",
        "\n",
        "# Using the output as a percentage\n",
        "\n",
        "Y = scaled_training_df[['TestTakersPercentage']].values\n",
        "\n",
        "\n",
        "# X = nytTraining.drop('NumSHSATTestTakers', axis=1).values\n",
        "# Y = nytTraining[['NumSHSATTestTakers']].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TaohpbCxKvMp",
        "colab_type": "code",
        "colab": {},
        "outputId": "60b9c841-4f34-425e-80d6-a0c0e6b34005"
      },
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "activationFuntion = 'relu'\n",
        "model.add(Dense(50, input_dim=numFeatures-1, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "# model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','accuracy'])\n",
        "\n",
        "\n",
        "#Train\n",
        "model.fit(\n",
        "    X,\n",
        "    Y,\n",
        "    epochs=50,\n",
        "    shuffle=True,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "X_test = scaled_testing_df.drop('TestTakersPercentage', axis=1).values\n",
        "Y_test = scaled_testing_df[['TestTakersPercentage']].values\n",
        "\n",
        "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "testErrorArray.append(test_error_rate)\n",
        "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n",
        "print(\"Here: \\n%s: %.5f%%\" % (model.metrics_names[2], test_error_rate[2]))\n",
        "\n",
        "model.save('savedModel.h5')\n",
        "print(\"Model Saved to Folder\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " - 1s - loss: 0.0138 - mean_absolute_error: 0.0621 - acc: 0.0067\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.0105 - mean_absolute_error: 0.0580 - acc: 0.0067\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.0096 - mean_absolute_error: 0.0498 - acc: 0.0067\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.0089 - mean_absolute_error: 0.0432 - acc: 0.0067\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.0082 - mean_absolute_error: 0.0470 - acc: 0.0067\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.0076 - mean_absolute_error: 0.0410 - acc: 0.0067\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.0072 - mean_absolute_error: 0.0443 - acc: 0.0067\n",
            "Epoch 8/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0399 - acc: 0.0067\n",
            "Epoch 9/50\n",
            " - 0s - loss: 0.0065 - mean_absolute_error: 0.0406 - acc: 0.0067\n",
            "Epoch 10/50\n",
            " - 0s - loss: 0.0063 - mean_absolute_error: 0.0422 - acc: 0.0067\n",
            "Epoch 11/50\n",
            " - 0s - loss: 0.0062 - mean_absolute_error: 0.0414 - acc: 0.0067\n",
            "Epoch 12/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0412 - acc: 0.0067\n",
            "Epoch 13/50\n",
            " - 0s - loss: 0.0065 - mean_absolute_error: 0.0520 - acc: 0.0067\n",
            "Epoch 14/50\n",
            " - 0s - loss: 0.0063 - mean_absolute_error: 0.0433 - acc: 0.0067\n",
            "Epoch 15/50\n",
            " - 0s - loss: 0.0057 - mean_absolute_error: 0.0425 - acc: 0.0067\n",
            "Epoch 16/50\n",
            " - 0s - loss: 0.0056 - mean_absolute_error: 0.0422 - acc: 0.0067\n",
            "Epoch 17/50\n",
            " - 0s - loss: 0.0057 - mean_absolute_error: 0.0381 - acc: 0.0067\n",
            "Epoch 18/50\n",
            " - 0s - loss: 0.0054 - mean_absolute_error: 0.0414 - acc: 0.0067\n",
            "Epoch 19/50\n",
            " - 0s - loss: 0.0050 - mean_absolute_error: 0.0358 - acc: 0.0067\n",
            "Epoch 20/50\n",
            " - 0s - loss: 0.0051 - mean_absolute_error: 0.0370 - acc: 0.0067\n",
            "Epoch 21/50\n",
            " - 0s - loss: 0.0051 - mean_absolute_error: 0.0361 - acc: 0.0067\n",
            "Epoch 22/50\n",
            " - 0s - loss: 0.0054 - mean_absolute_error: 0.0409 - acc: 0.0067\n",
            "Epoch 23/50\n",
            " - 0s - loss: 0.0052 - mean_absolute_error: 0.0378 - acc: 0.0067\n",
            "Epoch 24/50\n",
            " - 0s - loss: 0.0048 - mean_absolute_error: 0.0374 - acc: 0.0067\n",
            "Epoch 25/50\n",
            " - 0s - loss: 0.0048 - mean_absolute_error: 0.0372 - acc: 0.0067\n",
            "Epoch 26/50\n",
            " - 0s - loss: 0.0046 - mean_absolute_error: 0.0353 - acc: 0.0133\n",
            "Epoch 27/50\n",
            " - 0s - loss: 0.0046 - mean_absolute_error: 0.0372 - acc: 0.0133\n",
            "Epoch 28/50\n",
            " - 0s - loss: 0.0047 - mean_absolute_error: 0.0359 - acc: 0.0133\n",
            "Epoch 29/50\n",
            " - 0s - loss: 0.0047 - mean_absolute_error: 0.0395 - acc: 0.0133\n",
            "Epoch 30/50\n",
            " - 0s - loss: 0.0044 - mean_absolute_error: 0.0349 - acc: 0.0133\n",
            "Epoch 31/50\n",
            " - 0s - loss: 0.0044 - mean_absolute_error: 0.0344 - acc: 0.0133\n",
            "Epoch 32/50\n",
            " - 0s - loss: 0.0041 - mean_absolute_error: 0.0350 - acc: 0.0133\n",
            "Epoch 33/50\n",
            " - 0s - loss: 0.0043 - mean_absolute_error: 0.0332 - acc: 0.0133\n",
            "Epoch 34/50\n",
            " - 0s - loss: 0.0042 - mean_absolute_error: 0.0368 - acc: 0.0133\n",
            "Epoch 35/50\n",
            " - 0s - loss: 0.0042 - mean_absolute_error: 0.0329 - acc: 0.0133\n",
            "Epoch 36/50\n",
            " - 0s - loss: 0.0043 - mean_absolute_error: 0.0372 - acc: 0.0133\n",
            "Epoch 37/50\n",
            " - 0s - loss: 0.0042 - mean_absolute_error: 0.0325 - acc: 0.0133\n",
            "Epoch 38/50\n",
            " - 0s - loss: 0.0039 - mean_absolute_error: 0.0320 - acc: 0.0133\n",
            "Epoch 39/50\n",
            " - 0s - loss: 0.0038 - mean_absolute_error: 0.0329 - acc: 0.0133\n",
            "Epoch 40/50\n",
            " - 0s - loss: 0.0037 - mean_absolute_error: 0.0310 - acc: 0.0133\n",
            "Epoch 41/50\n",
            " - 0s - loss: 0.0038 - mean_absolute_error: 0.0352 - acc: 0.0133\n",
            "Epoch 42/50\n",
            " - 0s - loss: 0.0037 - mean_absolute_error: 0.0318 - acc: 0.0133\n",
            "Epoch 43/50\n",
            " - 0s - loss: 0.0035 - mean_absolute_error: 0.0309 - acc: 0.0133\n",
            "Epoch 44/50\n",
            " - 0s - loss: 0.0034 - mean_absolute_error: 0.0292 - acc: 0.0133\n",
            "Epoch 45/50\n",
            " - 0s - loss: 0.0034 - mean_absolute_error: 0.0323 - acc: 0.0133\n",
            "Epoch 46/50\n",
            " - 0s - loss: 0.0035 - mean_absolute_error: 0.0296 - acc: 0.0133\n",
            "Epoch 47/50\n",
            " - 0s - loss: 0.0039 - mean_absolute_error: 0.0367 - acc: 0.0133\n",
            "Epoch 48/50\n",
            " - 0s - loss: 0.0044 - mean_absolute_error: 0.0382 - acc: 0.0133\n",
            "Epoch 49/50\n",
            " - 0s - loss: 0.0039 - mean_absolute_error: 0.0421 - acc: 0.0133\n",
            "Epoch 50/50\n",
            " - 0s - loss: 0.0033 - mean_absolute_error: 0.0304 - acc: 0.0133\n",
            "The mean squared error (MSE) for the test data set is: [0.006273521361627469, 0.035230543758524094, 0.0]\n",
            "Here: \n",
            "acc: 0.00000%\n",
            "Model Saved to Folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DH0H-gjUKvMt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loading the saved model and then using it:\n",
        "\n",
        "model = load_model('savedModel.h5')\n",
        "\n",
        "# prediction = model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yBdWa2hRKvMx",
        "colab_type": "code",
        "colab": {},
        "outputId": "10ceecf3-7888-45de-87bd-3751ff5fe6e1"
      },
      "cell_type": "code",
      "source": [
        "X = pd.read_csv('kaggle-data/training_scaled.csv')\n",
        "\n",
        "\n",
        "X.head()\n",
        "\n",
        "X = X.loc[0:10]\n",
        "\n",
        "before = X[0:20]['TestTakersPercentage']\n",
        "X = X.drop('TestTakersPercentage',axis = 1)\n",
        "prediction = model.predict(X)\n",
        "# prediction = prediction + scaler.min_[0]\n",
        "prediction = prediction / scaler.scale_[0]\n",
        "\n",
        "\n",
        "print(before,prediction)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     0.092235\n",
            "1     0.115882\n",
            "2     1.000000\n",
            "3     0.226646\n",
            "4     0.510349\n",
            "5     0.102989\n",
            "6     0.123342\n",
            "7     0.134662\n",
            "8     0.087131\n",
            "9     0.075038\n",
            "10    0.079187\n",
            "Name: TestTakersPercentage, dtype: float64 [[0.8120292 ]\n",
            " [0.77867067]\n",
            " [4.939108  ]\n",
            " [1.6150904 ]\n",
            " [4.0077496 ]\n",
            " [0.69094396]\n",
            " [0.8725062 ]\n",
            " [1.1068518 ]\n",
            " [0.51014334]\n",
            " [0.7604499 ]\n",
            " [0.5523411 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}