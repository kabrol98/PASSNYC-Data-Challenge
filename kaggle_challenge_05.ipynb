{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle-challenge-05.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LMf7XJ8ZKvMI",
        "YsoiTEKBVRst"
      ]
    },
    "kernelspec": {
      "display_name": "Virtual Environment",
      "language": "python",
      "name": "virtualenvironment"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "LMf7XJ8ZKvMI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data"
      ]
    },
    {
      "metadata": {
        "id": "kQMLzJ8PMZKN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Going to import all libraries and upload all necessary files here.\n",
        "\n",
        "Uploading into colab. Setting up a virtual environment for myself is not an andeavor I'm interested in wasting this weekend on."
      ]
    },
    {
      "metadata": {
        "id": "Mp4l6P6sKvMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a194a137-14ef-4f61-96e8-8a18517c8b7c"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.models import load_model\n",
        "import io\n",
        "from google.colab import files\n",
        "import math\n",
        "import copy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rHTnX2_tSJmW",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "1df315dd-f987-4b8d-fa3e-d167b6c5aa19"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "school_data = pd.read_csv(io.StringIO(uploaded['2016 School Explorer.csv'].decode('utf-8')))\n",
        "# turnout_data = pd.read_csv(io.StringIO(uploaded['D5 SHSAT Registrations and Testers.csv'].decode('utf-8')))\n",
        "nytdf = pd.read_csv(io.StringIO(uploaded['nytdf.csv'].decode('utf-8')))\n",
        "middleschoolDirectory = pd.read_csv(io.StringIO(uploaded[\"2018_DOE_Middle_School_Directory.csv\"].decode('utf-8')))\n",
        "middleschoolAttendance = pd.read_csv(io.StringIO(uploaded[\"2016-2017_Monthly_Attendance.csv\"].decode('utf-8')))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd3db791-c257-4938-9350-001a6c3014b1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bd3db791-c257-4938-9350-001a6c3014b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 2016 School Explorer.csv to 2016 School Explorer.csv\n",
            "Saving 2016-2017_Monthly_Attendance.csv to 2016-2017_Monthly_Attendance.csv\n",
            "Saving 2018_DOE_Middle_School_Directory.csv to 2018_DOE_Middle_School_Directory.csv\n",
            "Saving D5 SHSAT Registrations and Testers.csv to D5 SHSAT Registrations and Testers.csv\n",
            "Saving nytdf.csv to nytdf.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ifU1CkS5BuDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ee11f4cf-9656-448f-ccb5-79f36cf080a5"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "middleschoolAttendance.head()\n",
        "\n",
        "year_8_attendance = middleschoolAttendance.query('GradeLevel == \\'08\\'')\n",
        "\n",
        "year_8_attendance.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>School</th>\n",
              "      <th>MonthCode</th>\n",
              "      <th>CalMonth</th>\n",
              "      <th>GradeLevel</th>\n",
              "      <th>GradeSort</th>\n",
              "      <th>RosterCount</th>\n",
              "      <th>Absent</th>\n",
              "      <th>Present</th>\n",
              "      <th>Released</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>01M034</td>\n",
              "      <td>5</td>\n",
              "      <td>Jan</td>\n",
              "      <td>08</td>\n",
              "      <td>8</td>\n",
              "      <td>62</td>\n",
              "      <td>131</td>\n",
              "      <td>1086</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>01M034</td>\n",
              "      <td>6</td>\n",
              "      <td>Feb</td>\n",
              "      <td>08</td>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>80</td>\n",
              "      <td>760</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>01M034</td>\n",
              "      <td>7</td>\n",
              "      <td>Mar</td>\n",
              "      <td>08</td>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>126</td>\n",
              "      <td>1175</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>01M034</td>\n",
              "      <td>8</td>\n",
              "      <td>Apr</td>\n",
              "      <td>08</td>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>80</td>\n",
              "      <td>697</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>01M034</td>\n",
              "      <td>9</td>\n",
              "      <td>May</td>\n",
              "      <td>08</td>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>95</td>\n",
              "      <td>1225</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     School  MonthCode CalMonth GradeLevel  GradeSort  RosterCount  Absent  \\\n",
              "217  01M034          5      Jan         08          8           62     131   \n",
              "227  01M034          6      Feb         08          8           60      80   \n",
              "237  01M034          7      Mar         08          8           60     126   \n",
              "247  01M034          8      Apr         08          8           60      80   \n",
              "257  01M034          9      May         08          8           60      95   \n",
              "\n",
              "     Present  Released  \n",
              "217     1086         0  \n",
              "227      760         0  \n",
              "237     1175         0  \n",
              "247      697         0  \n",
              "257     1225         0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "PwrAlJ9eKvMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "a4c5123c-7928-4123-8c25-169923c0fd78"
      },
      "cell_type": "code",
      "source": [
        "# Join all relevant dataframs\n",
        "schoolExplorer = school_data\n",
        "middleschoolDirectory = middleschoolDirectory.set_index('schooldbn')\n",
        "\n",
        "schoolExplorer = schoolExplorer.set_index('Location Code')\n",
        "nytdf = nytdf.set_index('DBN')\n",
        "\n",
        "explorer_nyt = schoolExplorer.join(nytdf)\n",
        "nytCombined = nytdf.join(schoolExplorer)\n",
        "\n",
        "nytCombined.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DataName</th>\n",
              "      <th>SchoolName1</th>\n",
              "      <th>SchoolName2</th>\n",
              "      <th>NumSHSATTestTakers</th>\n",
              "      <th>NumSpecializedOffers</th>\n",
              "      <th>OffersPerStudent</th>\n",
              "      <th>PctBlackOrHispanic</th>\n",
              "      <th>Adjusted Grade</th>\n",
              "      <th>New?</th>\n",
              "      <th>Other Location Code in LCGMS</th>\n",
              "      <th>...</th>\n",
              "      <th>Grade 8 Math - All Students Tested</th>\n",
              "      <th>Grade 8 Math 4s - All Students</th>\n",
              "      <th>Grade 8 Math 4s - American Indian or Alaska Native</th>\n",
              "      <th>Grade 8 Math 4s - Black or African American</th>\n",
              "      <th>Grade 8 Math 4s - Hispanic or Latino</th>\n",
              "      <th>Grade 8 Math 4s - Asian or Pacific Islander</th>\n",
              "      <th>Grade 8 Math 4s - White</th>\n",
              "      <th>Grade 8 Math 4s - Multiracial</th>\n",
              "      <th>Grade 8 Math 4s - Limited English Proficient</th>\n",
              "      <th>Grade 8 Math 4s - Economically Disadvantaged</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DBN</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20K187</th>\n",
              "      <td>THE CHRISTA MCAULIFFE SCHOOL\\I.S. 187</td>\n",
              "      <td>Intermediate School 187</td>\n",
              "      <td>The Christa McAuliffe School</td>\n",
              "      <td>251</td>\n",
              "      <td>205</td>\n",
              "      <td>75%</td>\n",
              "      <td>8%</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>339.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>196.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21K239</th>\n",
              "      <td>MARK TWAIN I.S. 239 FOR THE GIFTED &amp; TALENTED</td>\n",
              "      <td>Intermediate School 239</td>\n",
              "      <td>The Mark Twain Intermediate School for the Gif...</td>\n",
              "      <td>336</td>\n",
              "      <td>196</td>\n",
              "      <td>46%</td>\n",
              "      <td>13%</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>366.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>03M054</th>\n",
              "      <td>J.H.S. 054 BOOKER T. WASHINGTON</td>\n",
              "      <td>Junior High School 54</td>\n",
              "      <td>The Booker T. Washington School</td>\n",
              "      <td>257</td>\n",
              "      <td>150</td>\n",
              "      <td>53%</td>\n",
              "      <td>23%</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15K051</th>\n",
              "      <td>M.S. 51 WILLIAM ALEXANDER</td>\n",
              "      <td>Midde School 51</td>\n",
              "      <td>The William Alexander School</td>\n",
              "      <td>280</td>\n",
              "      <td>122</td>\n",
              "      <td>33%</td>\n",
              "      <td>28%</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>160.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02M312</th>\n",
              "      <td>NEW YORK CITY LAB MIDDLE SCHOOL FOR COLLABORAT...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New York City Lab Middle School for Collaborat...</td>\n",
              "      <td>163</td>\n",
              "      <td>113</td>\n",
              "      <td>62%</td>\n",
              "      <td>8%</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>42.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 167 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 DataName  \\\n",
              "DBN                                                         \n",
              "20K187              THE CHRISTA MCAULIFFE SCHOOL\\I.S. 187   \n",
              "21K239      MARK TWAIN I.S. 239 FOR THE GIFTED & TALENTED   \n",
              "03M054                    J.H.S. 054 BOOKER T. WASHINGTON   \n",
              "15K051                          M.S. 51 WILLIAM ALEXANDER   \n",
              "02M312  NEW YORK CITY LAB MIDDLE SCHOOL FOR COLLABORAT...   \n",
              "\n",
              "                    SchoolName1  \\\n",
              "DBN                               \n",
              "20K187  Intermediate School 187   \n",
              "21K239  Intermediate School 239   \n",
              "03M054    Junior High School 54   \n",
              "15K051          Midde School 51   \n",
              "02M312                      NaN   \n",
              "\n",
              "                                              SchoolName2  NumSHSATTestTakers  \\\n",
              "DBN                                                                             \n",
              "20K187                       The Christa McAuliffe School                 251   \n",
              "21K239  The Mark Twain Intermediate School for the Gif...                 336   \n",
              "03M054                    The Booker T. Washington School                 257   \n",
              "15K051                       The William Alexander School                 280   \n",
              "02M312  New York City Lab Middle School for Collaborat...                 163   \n",
              "\n",
              "        NumSpecializedOffers OffersPerStudent PctBlackOrHispanic  \\\n",
              "DBN                                                                \n",
              "20K187                   205              75%                 8%   \n",
              "21K239                   196              46%                13%   \n",
              "03M054                   150              53%                23%   \n",
              "15K051                   122              33%                28%   \n",
              "02M312                   113              62%                 8%   \n",
              "\n",
              "       Adjusted Grade New? Other Location Code in LCGMS  \\\n",
              "DBN                                                       \n",
              "20K187            NaN  NaN                          NaN   \n",
              "21K239            NaN  NaN                          NaN   \n",
              "03M054            NaN  NaN                          NaN   \n",
              "15K051            NaN  NaN                          NaN   \n",
              "02M312            NaN  NaN                          NaN   \n",
              "\n",
              "                           ...                       \\\n",
              "DBN                        ...                        \n",
              "20K187                     ...                        \n",
              "21K239                     ...                        \n",
              "03M054                     ...                        \n",
              "15K051                     ...                        \n",
              "02M312                     ...                        \n",
              "\n",
              "       Grade 8 Math - All Students Tested  Grade 8 Math 4s - All Students  \\\n",
              "DBN                                                                         \n",
              "20K187                              339.0                           312.0   \n",
              "21K239                              366.0                           209.0   \n",
              "03M054                               34.0                             1.0   \n",
              "15K051                              160.0                            37.0   \n",
              "02M312                               42.0                             7.0   \n",
              "\n",
              "        Grade 8 Math 4s - American Indian or Alaska Native  \\\n",
              "DBN                                                          \n",
              "20K187                                                0.0    \n",
              "21K239                                                0.0    \n",
              "03M054                                                0.0    \n",
              "15K051                                                0.0    \n",
              "02M312                                                0.0    \n",
              "\n",
              "        Grade 8 Math 4s - Black or African American  \\\n",
              "DBN                                                   \n",
              "20K187                                          0.0   \n",
              "21K239                                          5.0   \n",
              "03M054                                          0.0   \n",
              "15K051                                          5.0   \n",
              "02M312                                          0.0   \n",
              "\n",
              "        Grade 8 Math 4s - Hispanic or Latino  \\\n",
              "DBN                                            \n",
              "20K187                                   0.0   \n",
              "21K239                                   4.0   \n",
              "03M054                                   0.0   \n",
              "15K051                                   5.0   \n",
              "02M312                                   0.0   \n",
              "\n",
              "       Grade 8 Math 4s - Asian or Pacific Islander Grade 8 Math 4s - White  \\\n",
              "DBN                                                                          \n",
              "20K187                                       246.0                    59.0   \n",
              "21K239                                        98.0                    99.0   \n",
              "03M054                                         0.0                     0.0   \n",
              "15K051                                         0.0                    22.0   \n",
              "02M312                                         3.0                     3.0   \n",
              "\n",
              "        Grade 8 Math 4s - Multiracial  \\\n",
              "DBN                                     \n",
              "20K187                            0.0   \n",
              "21K239                            3.0   \n",
              "03M054                            0.0   \n",
              "15K051                            0.0   \n",
              "02M312                            0.0   \n",
              "\n",
              "       Grade 8 Math 4s - Limited English Proficient  \\\n",
              "DBN                                                   \n",
              "20K187                                          0.0   \n",
              "21K239                                          0.0   \n",
              "03M054                                          0.0   \n",
              "15K051                                          0.0   \n",
              "02M312                                          0.0   \n",
              "\n",
              "       Grade 8 Math 4s - Economically Disadvantaged  \n",
              "DBN                                                  \n",
              "20K187                                        196.0  \n",
              "21K239                                         65.0  \n",
              "03M054                                          0.0  \n",
              "15K051                                          8.0  \n",
              "02M312                                          1.0  \n",
              "\n",
              "[5 rows x 167 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "xrBfvek3eRDX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Picking, amending, and converting the necessary features into usable values for a predictive model."
      ]
    },
    {
      "metadata": {
        "id": "8qMLdsyIKvMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "45646739-0fc4-440d-99b4-688cab38b7d2"
      },
      "cell_type": "code",
      "source": [
        "#Pick features\n",
        "features = ['Percent of Students Chronically Absent','Average Math Proficiency','Economic Need Index','Average ELA Proficiency', 'Latitude', 'Longitude', 'NumSHSATTestTakers', 'Student Attendance Rate']\n",
        "target = 'NumSHSATTestTakers'\n",
        "\n",
        "nytCombinedFiltered = nytCombined.query('NumSHSATTestTakers != 0')\n",
        "\n",
        "nytCombinedFiltered[features].describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Average Math Proficiency</th>\n",
              "      <th>Economic Need Index</th>\n",
              "      <th>Average ELA Proficiency</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>NumSHSATTestTakers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>530.000000</td>\n",
              "      <td>531.000000</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>536.000000</td>\n",
              "      <td>536.000000</td>\n",
              "      <td>537.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.668849</td>\n",
              "      <td>0.657750</td>\n",
              "      <td>2.574906</td>\n",
              "      <td>40.738840</td>\n",
              "      <td>-73.915875</td>\n",
              "      <td>47.204842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.486156</td>\n",
              "      <td>0.191868</td>\n",
              "      <td>0.375443</td>\n",
              "      <td>0.086535</td>\n",
              "      <td>0.075129</td>\n",
              "      <td>61.158551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.890000</td>\n",
              "      <td>0.059000</td>\n",
              "      <td>1.910000</td>\n",
              "      <td>40.507803</td>\n",
              "      <td>-74.243221</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.270000</td>\n",
              "      <td>0.545500</td>\n",
              "      <td>2.280000</td>\n",
              "      <td>40.671637</td>\n",
              "      <td>-73.955888</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.610000</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>2.490000</td>\n",
              "      <td>40.728875</td>\n",
              "      <td>-73.919367</td>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.980000</td>\n",
              "      <td>0.806500</td>\n",
              "      <td>2.790000</td>\n",
              "      <td>40.820391</td>\n",
              "      <td>-73.880919</td>\n",
              "      <td>46.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.190000</td>\n",
              "      <td>0.938000</td>\n",
              "      <td>3.930000</td>\n",
              "      <td>40.899321</td>\n",
              "      <td>-73.713022</td>\n",
              "      <td>394.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Average Math Proficiency  Economic Need Index  Average ELA Proficiency  \\\n",
              "count                530.000000           531.000000               530.000000   \n",
              "mean                   2.668849             0.657750                 2.574906   \n",
              "std                    0.486156             0.191868                 0.375443   \n",
              "min                    1.890000             0.059000                 1.910000   \n",
              "25%                    2.270000             0.545500                 2.280000   \n",
              "50%                    2.610000             0.710000                 2.490000   \n",
              "75%                    2.980000             0.806500                 2.790000   \n",
              "max                    4.190000             0.938000                 3.930000   \n",
              "\n",
              "         Latitude   Longitude  NumSHSATTestTakers  \n",
              "count  536.000000  536.000000          537.000000  \n",
              "mean    40.738840  -73.915875           47.204842  \n",
              "std      0.086535    0.075129           61.158551  \n",
              "min     40.507803  -74.243221            6.000000  \n",
              "25%     40.671637  -73.955888           15.000000  \n",
              "50%     40.728875  -73.919367           26.000000  \n",
              "75%     40.820391  -73.880919           46.000000  \n",
              "max     40.899321  -73.713022          394.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "KEM3vGiUchZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper functions\n",
        "Set of functions to normalize data and remove percentages."
      ]
    },
    {
      "metadata": {
        "id": "wOz_0BSYcf36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert string valued percentages into floats within [0,1]\n",
        "def removePercent(df,columnNames):\n",
        "  for i in range(len(columnNames)):\n",
        "    col_string = df[columnNames[i]].str\n",
        "    df[columnNames[i]] = col_string.rstrip('%').astype('float') / 100.0\n",
        "    pass\n",
        "  return df\n",
        "  \n",
        "# for values in arbitrary ranges, normalize across [-1,1]\n",
        "def normalize_series(df, labels):\n",
        "  for label in labels:\n",
        "#     for sigma = 1 standard deviation, ~97% of datapoints should be within [-3sigma,sigma]\n",
        "    df[label] = (df[label] - df[label].mean()) / (3 * df[label].std())\n",
        "    pass\n",
        "  return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWuzcicOfX_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "68b248e9-7039-4ba5-bd17-4c182c3e0cbd"
      },
      "cell_type": "code",
      "source": [
        "# Applying helpers to dataset\n",
        "\n",
        "nytApplyFilters = removePercent(nytCombinedFiltered.copy(), ['Student Attendance Rate', 'Percent of Students Chronically Absent'])\n",
        "\n",
        "nytApplyFilters = normalize_series(nytApplyFilters, ['Average Math Proficiency', 'Average ELA Proficiency', 'Latitude', 'Longitude'])\n",
        "\n",
        "nytApplyFilters = nytApplyFilters.dropna(subset=[target])\n",
        "nytApplyFilters.fillna(0,inplace = True)\n",
        "\n",
        "nytApplyFilters[features].describe()\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Percent of Students Chronically Absent</th>\n",
              "      <th>Average Math Proficiency</th>\n",
              "      <th>Economic Need Index</th>\n",
              "      <th>Average ELA Proficiency</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>NumSHSATTestTakers</th>\n",
              "      <th>Student Attendance Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>537.000000</td>\n",
              "      <td>5.370000e+02</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>5.370000e+02</td>\n",
              "      <td>5.370000e+02</td>\n",
              "      <td>5.370000e+02</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.196108</td>\n",
              "      <td>7.939025e-17</td>\n",
              "      <td>0.650400</td>\n",
              "      <td>-2.514025e-16</td>\n",
              "      <td>1.860378e-14</td>\n",
              "      <td>-5.659532e-14</td>\n",
              "      <td>47.204842</td>\n",
              "      <td>0.913762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.150459</td>\n",
              "      <td>3.311496e-01</td>\n",
              "      <td>0.202953</td>\n",
              "      <td>3.311496e-01</td>\n",
              "      <td>3.330222e-01</td>\n",
              "      <td>3.330222e-01</td>\n",
              "      <td>61.158551</td>\n",
              "      <td>0.151724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.340184e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.903301e-01</td>\n",
              "      <td>-8.899587e-01</td>\n",
              "      <td>-1.452364e+00</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>-2.666146e-01</td>\n",
              "      <td>0.538000</td>\n",
              "      <td>-2.618291e-01</td>\n",
              "      <td>-2.579054e-01</td>\n",
              "      <td>-1.773479e-01</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.170000</td>\n",
              "      <td>-3.349339e-02</td>\n",
              "      <td>0.708000</td>\n",
              "      <td>-7.538267e-02</td>\n",
              "      <td>-3.731623e-02</td>\n",
              "      <td>-1.418521e-02</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.270000</td>\n",
              "      <td>2.133409e-01</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>1.820910e-01</td>\n",
              "      <td>3.133669e-01</td>\n",
              "      <td>1.541464e-01</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.042978e+00</td>\n",
              "      <td>0.938000</td>\n",
              "      <td>1.203107e+00</td>\n",
              "      <td>6.181726e-01</td>\n",
              "      <td>9.000141e-01</td>\n",
              "      <td>394.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Percent of Students Chronically Absent  Average Math Proficiency  \\\n",
              "count                              537.000000              5.370000e+02   \n",
              "mean                                 0.196108              7.939025e-17   \n",
              "std                                  0.150459              3.311496e-01   \n",
              "min                                  0.000000             -5.340184e-01   \n",
              "25%                                  0.100000             -2.666146e-01   \n",
              "50%                                  0.170000             -3.349339e-02   \n",
              "75%                                  0.270000              2.133409e-01   \n",
              "max                                  1.000000              1.042978e+00   \n",
              "\n",
              "       Economic Need Index  Average ELA Proficiency      Latitude  \\\n",
              "count           537.000000             5.370000e+02  5.370000e+02   \n",
              "mean              0.650400            -2.514025e-16  1.860378e-14   \n",
              "std               0.202953             3.311496e-01  3.330222e-01   \n",
              "min               0.000000            -5.903301e-01 -8.899587e-01   \n",
              "25%               0.538000            -2.618291e-01 -2.579054e-01   \n",
              "50%               0.708000            -7.538267e-02 -3.731623e-02   \n",
              "75%               0.806000             1.820910e-01  3.133669e-01   \n",
              "max               0.938000             1.203107e+00  6.181726e-01   \n",
              "\n",
              "          Longitude  NumSHSATTestTakers  Student Attendance Rate  \n",
              "count  5.370000e+02          537.000000               537.000000  \n",
              "mean  -5.659532e-14           47.204842                 0.913762  \n",
              "std    3.330222e-01           61.158551                 0.151724  \n",
              "min   -1.452364e+00            6.000000                 0.000000  \n",
              "25%   -1.773479e-01           15.000000                 0.920000  \n",
              "50%   -1.418521e-02           26.000000                 0.940000  \n",
              "75%    1.541464e-01           46.000000                 0.960000  \n",
              "max    9.000141e-01          394.000000                 1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "MaEejyNxoPyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setting up features as a vector\n",
        "# Separating training and testing for k-fold vallidation\n",
        "num_folds = 10\n",
        "N = nytApplyFilters.shape[0]\n",
        "\n",
        "test_set = nytApplyFilters[0: N / num_folds]\n",
        "train_set = nytApplyFilters[N / num_folds : N]\n",
        "\n",
        "test_set = test_set.filter(features)\n",
        "train_set = train_set.filter(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mkygk68pq3Q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "45f0c6a2-7525-4b4a-d579-1dabd7192688"
      },
      "cell_type": "code",
      "source": [
        "# X and Y from train sets\n",
        "\n",
        "X = train_set.drop(target, axis=1).values\n",
        "\n",
        "# Using the output as a percentage\n",
        "\n",
        "Y = train_set[[target]].values\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(484, 7)\n",
            "(484, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BrNily2drusm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Neural Network\n"
      ]
    },
    {
      "metadata": {
        "id": "4QFsFK9wrt0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "96c31223-fd64-4046-f5bf-5b1b72d670e2"
      },
      "cell_type": "code",
      "source": [
        "numFeatures = len(features)\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "activationFuntion = 'relu'\n",
        "model.add(Dense(20, input_dim=numFeatures-1, activation='relu'))\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "# model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','accuracy'])\n",
        "\n",
        "\n",
        "#Train\n",
        "model.fit(\n",
        "    X,\n",
        "    Y,\n",
        "    epochs=200,\n",
        "    shuffle=True,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "\n",
        "X_test = test_set.drop(target, axis=1).values\n",
        "Y_test = test_set[[target]].values\n",
        "\n",
        "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "testErrorArray.append(test_error_rate)\n",
        "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n",
        "print(\"Here: \\n%s: %.8f%%\" % (model.metrics_names[2], test_error_rate[2]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean squared error (MSE) for the test data set is: [28634.947302476416, 142.72677036501327, 0.0]\n",
            "Here: \n",
            "acc: 0.00000000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W99G64DAUbSJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Best \"acc\" achieved by this prediction network: 0.01887%.\n",
        "Best MSE on real valued Num of SHSAT Test Takers: 142.65"
      ]
    },
    {
      "metadata": {
        "id": "odaWq-BYUmLn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Radial Basis Function (RBF) Model\n",
        "\n",
        "I'm going to try a Radial Basis Function Model to minimize in-sample Mean Squared Error.\n",
        "\n",
        "Value to beat: 142.65."
      ]
    },
    {
      "metadata": {
        "id": "YsoiTEKBVRst",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Intuition\n",
        "\n",
        "You may not feel the connection immediately, even by looking at the math, but I think of radial basis functions as probability distributions around certain points.\n",
        "\n",
        "This is the function I've chosen; I've chosen it because the brilliant Dr. Abu Mustafa of the online Caltech ML course on YouTube picked it out when explaining the math behind this. My whole model is based around it:\n",
        "\n",
        "\\begin{equation}\n",
        "\\Large\n",
        "f(\\mathbf{x}) = \\sum_{k=1}^K w_ke^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_k} \\| ^ 2}\n",
        "\\end{equation}"
      ]
    },
    {
      "metadata": {
        "id": "Utq8_5O4dSNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "What does this mean? Well, basically, it follows directly from the idea of continuity. What if our target function predicting $y$ was continuous? If that were true, then for a point at a certain location, we could assume that points close to that location would be kind of close to the value at that location. It's becomes a cumulative probability distribution, where every point in the training set is understood to have an area of influence that tapers off based on how far away an input is from that point. It also has a weight, or the value that area of influence imposes on the input.\n",
        "\n",
        "So the influence on any input $ x $ is dependent on the exponential distribution to a given point $ \\mu $ by the following equation:\n",
        "\n",
        "$\n",
        "\\begin{equation}\n",
        "\\large\n",
        "\\forall \\mu, f(\\mathbf{x}) \\propto e^{-\\lambda \\mathbf{ \\| x - \\mu \\| } ^ 2}\n",
        "\\end{equation}\n",
        "$\n"
      ]
    },
    {
      "metadata": {
        "id": "CGRN6SR6dWM6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now in this case $ \\lambda$ is the rate at which the influence of any given point tapers off as the input moves farther away for a $\\mu$. Changing the value of lambda decides how far close to each $\\mu$ an input has to be to get the influence.\n",
        "and by that logic, we can conclude that if we have $K$ $\\mu$'s,\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\large\n",
        "f(\\mathbf{x}) = \\sum_{k=1}^K w_ke^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_k} \\| ^ 2}\n",
        "\\end{equation}\n",
        "\n",
        "Notice how I've been really deliberate in calling each point $\\mu$. If you know some statistics you picked up on the fact that its a symbol that denotes a mean. The reason for this is simply to improve on computation. Some datasets have records on the order of $10^5$. That's ridiculous, and it would make no sense to to run the whole calculation. So instead we generate a set of $K$ different $\\mu$s, or 'K-means'. These means are representative points for the entire dataset given to us. I haven't come across any specific rule of thumb while choosing $K$, so what I'm going to do is have $K \\propto \\log{N}$. After all, the whole point of having $K$ is to reduce the number of computations you have to go through."
      ]
    },
    {
      "metadata": {
        "id": "k8ev1VnH7v0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Process\n"
      ]
    },
    {
      "metadata": {
        "id": "JERJGOtzhRl6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 1:\n",
        "K-means clustering on feature sets.\n",
        "\n",
        "### Step 2:\n",
        "Define the RBF equation as follows.\n",
        "\n",
        "\\begin{equation}\n",
        "\\large\n",
        "y = \\sum_{k=1}^K w_ke^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_k} \\| ^ 2}\n",
        "\\end{equation}\n",
        "\n",
        "with precision rate $\\lambda$ where $\\mu_k$ is a mean point for all $K$- means.\n",
        "\n",
        "### Step 3:\n",
        "Build model to find least square values for all weights $w_k$.\n",
        "\n",
        "### Step 4:\n",
        "Test model with different precision rates, try to minimize cost."
      ]
    },
    {
      "metadata": {
        "id": "ueUm9Y8vcQhl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: K means clustering"
      ]
    },
    {
      "metadata": {
        "id": "01zZZBP_MCDl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Lloyd's algorithm\n",
        "I'm going to implement K-means clustering using Lloyd's algorithm on the feature vector $ \\mathbf{x} $,\n",
        "using the following iterative implementation for Lloyd's algotihm.\n",
        "\n",
        "$ \\mathbf{\\mu_0} = random \\in {\\mathbf{x}}$\n",
        "\n",
        "$ \\mathbf{S_0} =  \\{ \\mathbf{x} : \\forall \\mu, \\| \\mathbf{x} - \\mathbf{\\mu_0} \\| \\leq \\| \\mathbf{x} - \\mathbf{\\mu} \\|\\} $\n",
        "\n",
        "$ \\mathbf{\\mu_{n+1}} = \\frac{1}{\\mathbf{\\|S_n\\|}} \\sum_{\\mathbf{x} \\in \\mathbf{S_n}} \\mathbf{x}$\n",
        "\n",
        "$ \\mathbf{S_{n+1}} =  \\{ \\mathbf{x} : \\forall \\mu, \\| \\mathbf{x} - \\mathbf{\\mu_{n+1}} \\| \\leq \\| \\mathbf{x} - \\mathbf{\\mu} \\|\\} $\n"
      ]
    },
    {
      "metadata": {
        "id": "qMIPF-qxcOZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Lloyd's algorithm: Implmentation.\n",
        "# Assume feature engineering has been done.\n",
        "class LloydMeans:\n",
        "  \n",
        "  def __init__ (self, k, df, labels):\n",
        "    self.pointMatrix = df[labels].as_matrix()\n",
        "    self.df = df\n",
        "    self.labels = labels\n",
        "    self.k = k\n",
        "    pass\n",
        "  \n",
        "  def assign_means(self, num_trials, num_iterations):\n",
        "    best_error = float(\"inf\") # Best error is positive infinity\n",
        "    best_mu = []\n",
        "    best_meanSet = []\n",
        "    clustered_features = self.labels\n",
        "    pointMatrix = self.pointMatrix\n",
        "    k = self.k\n",
        "    df = self.df\n",
        "\n",
        "    for trial in range(num_trials):\n",
        "      mu = self.init_mu(df, clustered_features, k)\n",
        "\n",
        "      for i in range(num_iterations):\n",
        "        #iteratively update the clusters and cluster means nunm_iterations times\n",
        "        meanSet = self.update_clusters(pointMatrix, mu, k)\n",
        "        mu = self.update_cluster_points(meanSet, mu, k)\n",
        "        pass\n",
        "\n",
        "      #calculate error of current mu model\n",
        "      model_error = self.calculate_total_error(meanSet, mu)\n",
        "\n",
        "      print(\"MSE for trial {} : {}\".format(trial, model_error))\n",
        "\n",
        "      #always take the best model w/ minimum error\n",
        "      if(model_error < best_error):\n",
        "        best_error = model_error\n",
        "        best_mu = mu\n",
        "        best_meanSet = meanSet\n",
        "        pass\n",
        "      pass\n",
        "    print(\"Best error is {}\".format(best_error))\n",
        "#     df = assign_final_clusters(pointMatrix, best_mu, k, self.df)\n",
        "    return best_mu\n",
        "  \n",
        "  def normalize_matrix(self, df, labels):\n",
        "    mat = df[labels].as_matrix()\n",
        "    # transform all datapoints so ~97% of values are in [-1, 1]\n",
        "    for i in range(mat.shape[0]):\n",
        "      for j in range(mat.shape[1]):\n",
        "        mat[i][j] = (mat[i][j] - df[labels[j]].mean()) / (3 * df[labels[j]].std())\n",
        "        pass\n",
        "      pass\n",
        "    return mat\n",
        "\n",
        "  def init_mu(self, df, labels, k):\n",
        "      mu = np.zeros((k, len(labels)))\n",
        "      for i in range(len(labels)):\n",
        "        for j in range(k):\n",
        "#           initialize random float in [-1, 1]\n",
        "          offset = np.random.ranf() * 6 - 3\n",
        "          mu[j][i] = df[labels[i]].mean() + offset\n",
        "      return mu\n",
        "\n",
        "  def update_clusters(self, pointMatrix, mu, k):\n",
        "    meanSet = [[] for i in range(k)]\n",
        "  #   iterate over points\n",
        "    for i in range(pointMatrix.shape[0]):\n",
        "      minIndex = 0\n",
        "      minDistance = np.linalg.norm(pointMatrix[i] - mu[minIndex])\n",
        "  #     iterate over mu (mean points)\n",
        "      for j in range(k):\n",
        "        dist = np.linalg.norm(pointMatrix[i] - mu[j])\n",
        "  #       pick j with the minimum distance from i\n",
        "        if(dist < minDistance):\n",
        "          minDistance = dist\n",
        "          minIndex = j\n",
        "          pass\n",
        "        pass\n",
        "    #   Add point i to mu[j]'s cluster'\n",
        "      meanSet[minIndex].append(pointMatrix[i])\n",
        "      pass\n",
        "    return meanSet\n",
        "\n",
        "  def assign_final_clusters(self, pointMatrix, mu, k, df):\n",
        "  #   iterate over points (repeating update_clusters)\n",
        "    for i in range(pointMatrix.shape[0]):\n",
        "      minIndex = 0\n",
        "      minDistance = np.linalg.norm(pointMatrix[i] - mu[minIndex])\n",
        "  #     iterate over mu (mean points)\n",
        "      for j in range(k):\n",
        "        dist = np.linalg.norm(pointMatrix[i] - mu[j])\n",
        "  #       pick j with the minimum distance from i\n",
        "        if(dist < minDistance):\n",
        "          minDistance = dist\n",
        "          minIndex = j\n",
        "          pass\n",
        "        pass\n",
        "    #   Assign final cluster values to dataframe\n",
        "      df.loc[df.index[i], 'cluster'] = minIndex\n",
        "      pass\n",
        "    return df\n",
        "\n",
        "  def update_cluster_points(self, meanSet, mu, k):\n",
        "  #   iterate over mu\n",
        "    for i in range(k):\n",
        "      set_sum = np.zeros(mu[i].shape)\n",
        "  #     iterate over mu[i]'s cluster'\n",
        "      for j in range(len(meanSet[i])):\n",
        "        # sum up all the positions of each point\n",
        "        set_sum += meanSet[i][j]\n",
        "        pass\n",
        "      # update mu to the average of each point in mu's cluster\n",
        "      if len(meanSet[i]) != 0:\n",
        "        mu[i] = set_sum / len(meanSet[i])\n",
        "        pass\n",
        "      pass\n",
        "    return mu\n",
        "\n",
        "  def calculate_total_error(self, meanSet, mu):\n",
        "    mserror = 0\n",
        "    N = 0\n",
        "    for i in range(self.k):\n",
        "      for j in range(len(meanSet[i])):\n",
        "        error = np.linalg.norm(meanSet[i][j] - mu[i])\n",
        "        mserror += error * error\n",
        "        N += 1\n",
        "        pass\n",
        "      pass\n",
        "    return mserror / N\n",
        "  \n",
        "  pass\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yyosdWSgSk_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "01d28b99-0f5c-47fa-eff3-8f96f1ca75f3"
      },
      "cell_type": "code",
      "source": [
        "# Lloyd's Algorithm- application\n",
        "\n",
        "# Set up X as independent dataframe with features vector\n",
        "clusterDF = train_set\n",
        "featureLabels = copy.deepcopy(features)\n",
        "featureLabels.remove(target)\n",
        "\n",
        "# Let K increase logarithmically with N.\n",
        "# This will help optimize clustering and create good representatives.\n",
        "\n",
        "train_N = clusterDF.shape[0]\n",
        "K = 3 * int(math.floor(math.log(train_N)))\n",
        "\n",
        "lloyd = LloydMeans(K, clusterDF, featureLabels)\n",
        "mu = lloyd.assign_means(num_iterations = 30, num_trials = 10)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE for trial 0 : 0.298685040628\n",
            "MSE for trial 1 : 0.266339387005\n",
            "MSE for trial 2 : 0.333427530396\n",
            "MSE for trial 3 : 0.234696350861\n",
            "MSE for trial 4 : 0.196459265037\n",
            "MSE for trial 5 : 0.134504473204\n",
            "MSE for trial 6 : 0.194978893949\n",
            "MSE for trial 7 : 0.420899217507\n",
            "MSE for trial 8 : 0.227243313196\n",
            "MSE for trial 9 : 0.193500006943\n",
            "Best error is 0.134504473204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qLe05DkAn8gj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Defining the Radial Basis Function"
      ]
    },
    {
      "metadata": {
        "id": "2pCx-7iyL7or",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is the function again, just to remind myself, and because LaTEX is awesome.\n",
        "\n",
        "\\begin{equation}\n",
        "\\large\n",
        "f(\\mathbf{x}) = \\sum_{k=1}^K w_ke^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_k} \\| ^ 2}\n",
        "\\end{equation}\n",
        "\n",
        "**Note: $\\lambda$ in the code is \"precision_rate\". This is because the phrase \"lambda\" reads as the start of a lambda function, so I can't use it to name a variable.**"
      ]
    },
    {
      "metadata": {
        "id": "iwKcfGqHnatV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _predict (mu, w, x, precision_rate):\n",
        "#   Sum over mu\n",
        "  sum = 0\n",
        "  for i in range(mu.shape[0]):\n",
        "#     distance between point x and mu\n",
        "    dist = np.linalg.norm(x - mu[i])\n",
        "#   square distance, multiply by lambda\n",
        "    exponent = (- precision_rate) * dist * dist\n",
        "#   multiply exponent by weight, add to total\n",
        "    sum += (w[i] * math.exp(exponent))\n",
        "    pass\n",
        "  return sum\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1C_y7Kbv-wt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a good start, but we have to visualize this as a matrix instead of a function before we can solve for $ \\mathbf{w} $\n",
        "\n",
        "We're going to do this by creating the following matrix:\n",
        "\n",
        "$\\mathbf{A_{1,K}} = \n",
        "\\begin{pmatrix} \n",
        "e^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_1} \\| ^ 2} & \\cdots & e^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_K} \\| ^ 2}\n",
        "\\end{pmatrix}$\n",
        "\n",
        "This way, the new equation is:\n",
        "$\n",
        "\\begin{equation}\n",
        "\\begin{bmatrix} \n",
        "e^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_1} \\| ^ 2} & \\cdots & e^{-\\lambda \\| \\mathbf{x} - \\mathbf{\\mu_K} \\| ^ 2}\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "w_1 \\\\ \\vdots \\\\ w_K\n",
        "\\end{bmatrix} = y\n",
        "\\end{equation}\n",
        "$\n",
        "\n",
        "or\n",
        "\n",
        "$\\begin{equation} \\mathbf{Aw} = y \\end{equation}$"
      ]
    },
    {
      "metadata": {
        "id": "DvOVtGX2ogU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict (mu, w, x, precision_rate):\n",
        "  A = np.zeros((1, mu.shape[0]))\n",
        "  for i in range(mu.shape[0]):\n",
        "#   distance between point x and mu\n",
        "    dist = np.linalg.norm(x - mu[i])\n",
        "#   square distance, multiply by lambda\n",
        "    exponent = (- precision_rate) * dist * dist\n",
        "    A[0][i] = math.exp(exponent)\n",
        "    pass\n",
        "  return np.dot(A, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WiiU8GRvjmpW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Training.\n"
      ]
    },
    {
      "metadata": {
        "id": "6YnFaazULwcq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is going to be the most fun part.\n",
        "Extend our previous matrix $ \\mathbf{A} $ to all N points in our dataset, creating a K by N matrix.\n",
        "\n",
        "$\\mathbf{A_{N,K}} = \n",
        "\\begin{bmatrix} \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_1} \\| ^ 2} & \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_2} \\| ^ 2} & \\cdots & \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_K} \\| ^ 2} \n",
        "\\\\\n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_1} \\| ^ 2} & \n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_2} \\| ^ 2} & \\cdots &\n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_K} \\| ^ 2}\n",
        "\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\n",
        "\\\\\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_1} \\| ^ 2} &\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_2} \\| ^ 2} &\\cdots &\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_K} \\| ^ 2} \n",
        "\\end{bmatrix}$\n",
        "\n",
        "Now,\n",
        "\n",
        "$\n",
        "\\begin{bmatrix} \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_1} \\| ^ 2} & \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_2} \\| ^ 2} & \\cdots & \n",
        "e^{-\\lambda \\| \\mathbf{x_1} - \\mathbf{\\mu_K} \\| ^ 2} \n",
        "\\\\\n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_1} \\| ^ 2} & \n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_2} \\| ^ 2} & \\cdots &\n",
        "e^{-\\lambda \\| \\mathbf{x_2} - \\mathbf{\\mu_K} \\| ^ 2}\n",
        "\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\n",
        "\\\\\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_1} \\| ^ 2} &\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_2} \\| ^ 2} &\\cdots &\n",
        "e^{-\\lambda \\| \\mathbf{x_N} - \\mathbf{\\mu_K} \\| ^ 2} \n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_K\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N\n",
        "\\end{bmatrix}$\n",
        "\n",
        "or,\n",
        "\n",
        "$ \\mathbf{Aw = y} $\n",
        "\n",
        "So, to solve for $ \\mathbf{w} $ given a reasonable lambda we use the old Math 415 least squares regression equation\n",
        "\n",
        "$\\begin{equation}\n",
        "\\mathbf{w = (A^TA)^{-1}A^Ty}\n",
        "\\end{equation}\n",
        "$\n",
        "\n",
        "We're also going to write a loss function to look for a good MSE"
      ]
    },
    {
      "metadata": {
        "id": "5s3asd572CnR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train (X, Y, precision_rate, mu):\n",
        "  A = np.zeros((X.shape[0], mu.shape[0]))\n",
        "#   iterate over X\n",
        "  for i in range(X.shape[0]):\n",
        "#     iterate over mu\n",
        "    for j in range(mu.shape[0]):\n",
        "#     create vectors for x and mu\n",
        "      _x = np.transpose([X[i]])\n",
        "      _mu = np.transpose([mu[j]])\n",
        "#     Take the distance between point x and mu\n",
        "      dist = np.linalg.norm(_x - _mu)\n",
        "  #   square distance, multiply by lambda\n",
        "      exponent = (- precision_rate) * dist * dist\n",
        "      A[i][j] = math.exp(exponent)\n",
        "      pass\n",
        "    pass\n",
        "  \n",
        "#   Get ATA\n",
        "  transpose = np.transpose(A)\n",
        "  ATA = np.dot(transpose, A)\n",
        "  \n",
        "#   Invert ATA\n",
        "  pseudoInv = np.linalg.inv(ATA)\n",
        "  \n",
        "#   Take(ATA)^-1 ATy\n",
        "  res = np.dot(transpose, Y)\n",
        "  res = np.dot(pseudoInv, res)\n",
        "  return res\n",
        "  \n",
        "  \n",
        "def get_loss(X, Y, precision_rate, mu, w):\n",
        "  mse = 0\n",
        "  count = 0\n",
        "  for i in range(X.shape[0]):\n",
        "    predicted = predict(mu, w, X[i], precision_rate)\n",
        "    err = Y[i] - predicted\n",
        "    mse += err * err\n",
        "    count += 1\n",
        "    pass\n",
        "  res = mse / count\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXYFITEc4rVX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4: Application\n",
        "I've now written more latex than code and tested none of the code. Let's see if anything happens.\n",
        "I'm going to put everything in a for loop that tries different lambdas"
      ]
    },
    {
      "metadata": {
        "id": "w5rKOr334pm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "37ec304b-96df-483e-9484-c572300e9def"
      },
      "cell_type": "code",
      "source": [
        "step = 0.00001\n",
        "precision_rate = 0.00040\n",
        "X = train_set.drop(target, axis=1).values\n",
        "Y = train_set[[target]].values\n",
        "\n",
        "test_X = test_set.drop(target, axis=1).values\n",
        "test_Y = test_set[[target]].values\n",
        "\n",
        "best_precision = precision_rate\n",
        "best_error = float('inf')\n",
        "\n",
        "for i in range(20):\n",
        "#   Train for given precision rate\n",
        "  w = train(X, Y, precision_rate, mu)\n",
        "#   Get the error\n",
        "  current_error = get_loss(test_X, test_Y, precision_rate, mu, w)\n",
        "  print('MSE for lambda {} was {}'.format(precision_rate, current_error))\n",
        "  \n",
        "#   Replace the best error and rate if a better set is found\n",
        "  if current_error < best_error:\n",
        "    best_error = current_error\n",
        "    best_precision = precision_rate\n",
        "    pass\n",
        "  precision_rate += step\n",
        "  pass\n",
        "\n",
        "print('Best MSE was {} with precision rate {}'.format(best_error, best_precision))\n",
        "  "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE for lambda 0.0004 was [[23364.19028572]]\n",
            "MSE for lambda 0.00041 was [[30615.24351231]]\n",
            "MSE for lambda 0.00042 was [[30990.33993122]]\n",
            "MSE for lambda 0.00043 was [[29834.65088792]]\n",
            "MSE for lambda 0.00044 was [[34570.28670739]]\n",
            "MSE for lambda 0.00045 was [[15223.95151741]]\n",
            "MSE for lambda 0.00046 was [[32258.74713654]]\n",
            "MSE for lambda 0.00047 was [[26031.41274639]]\n",
            "MSE for lambda 0.00048 was [[24854.02090768]]\n",
            "MSE for lambda 0.00049 was [[18074.24314273]]\n",
            "MSE for lambda 0.0005 was [[30316.2872158]]\n",
            "MSE for lambda 0.00051 was [[37912.11468348]]\n",
            "MSE for lambda 0.00052 was [[38603.36329608]]\n",
            "MSE for lambda 0.00053 was [[39027.81584456]]\n",
            "MSE for lambda 0.00054 was [[24340.78643773]]\n",
            "MSE for lambda 0.00055 was [[64318.54806516]]\n",
            "MSE for lambda 0.00056 was [[17470.2264807]]\n",
            "MSE for lambda 0.00057 was [[228043.10727811]]\n",
            "MSE for lambda 0.00058 was [[30590.36875535]]\n",
            "MSE for lambda 0.00059 was [[32339.58994068]]\n",
            "Best MSE was [[15223.95151741]] with precision rate 0.00045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0q8gGiVkIZ4c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Review:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "lCFAVnEihrnT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### ...Fuck.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "MSE for lambda 0.00055 was [[64318.54806516]]\n",
        "MSE for lambda 0.00056 was [[17470.2264807]]\n",
        "MSE for lambda 0.00057 was [[228043.10727811]]\n",
        "MSE for lambda 0.00058 was [[30590.36875535]]\n",
        "MSE for lambda 0.00059 was [[32339.58994068]]\n",
        "Best MSE was [[15223.95151741]] with precision rate 0.00045\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "iuoGZY80Lnwj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Possible issues:\n",
        " - N too small.\n",
        " - K too small.\n",
        " - Features are too few.\n",
        " - lambda uniform across means.\n",
        " - model not complex enough.\n",
        " - Some stupid mistake somewhere scales values wrong. You know, by a factor of $10^5$.\n",
        " \n",
        "#### Possible Solutions:\n",
        "  - Fuck this dataset. This dataset is horrible. 400 points, 7 features.\n",
        "  - Try to find/ implement variable lambda, and use iterative algorithm to regress w and lambda\n",
        "  - Implement RBF Network with multiple layers. This would be ridiculous in terms of debugging and time commitment."
      ]
    },
    {
      "metadata": {
        "id": "w7Aj2591U-b4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Step 5: Multiple $ \\lambda$s\n",
        "\n",
        "The thing about the radial basis function is that it works on distributions with two values, not one. Some points should have stronger influence areas than others. But our model applies a single $ \\lambda$ to all means.\n",
        "\n",
        "Now I'm going to try to beat the ridiculous MSE from the single $\\lambda$ model of 15223.95151741 by using multiple $\\lambda$s, so the new function will be as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\large\n",
        "f(\\mathbf{x}) = \\sum_{k=1}^K w_ke^{-\\lambda_k \\| \\mathbf{x} - \\mathbf{\\mu_k} \\| ^ 2}\n",
        "\\end{equation}\n",
        "\n",
        "Here's the thing: this is a LOT more complicated than it looks.\n",
        "When we were optimizing for the linear weight vector $\\mathbf{w}$, we were able to pull off a basic linear algebra trick, but lambda affects the equiation nonlinearly. That means the only way to train this model is through stochastic gradient descent, which can be done, but it is in no way ideal in this situation and is going to depend entirely on how accurate my math is."
      ]
    }
  ]
}